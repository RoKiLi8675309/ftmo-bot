# =============================================================================
# FILENAME: engines/live/predictor.py
# ENVIRONMENT: Linux/WSL2 (Python 3.11)
# PATH: engines/live/predictor.py
# DEPENDENCIES: shared, river, numpy
# DESCRIPTION: Online Learning Kernel. Manages Ensemble Models (Bagging ARF),
# Feature Engineering, Labeling (Adaptive Triple Barrier), and Weighted Learning.
#
# PHOENIX STRATEGY UPGRADE (2025-12-25 - RETAIL FALLBACK):
# 1. FALLBACK: Auto-detects missing L2 data (zero buy/sell vol).
# 2. TICK RULE: Uses Price Delta to estimate flow if L2 is missing.
# 3. ROBUSTNESS: Prevents "OFI Wait" freeze on Demo accounts.
# =============================================================================
import logging
import pickle
import os
import json
import time
import math
from collections import defaultdict, deque, Counter
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

# Third-Party ML Imports
try:
    from river import forest, compose, preprocessing, metrics, drift, linear_model, multioutput, ensemble
except ImportError:
    print("CRITICAL: 'river' library not found. Install with: pip install river>=0.21.0")
    import sys
    sys.exit(1)

# Shared Imports
from shared import (
    CONFIG,
    LogSymbols,
    OnlineFeatureEngineer,
    AdaptiveTripleBarrier,
    ProbabilityCalibrator,
    enrich_with_d1_data,
    VolumeBar,
    RiskManager
)

# New Feature Import
from shared.financial.features import MetaLabeler

logger = logging.getLogger("Predictor")

class Signal:
    """
    Represents a trading decision generated by the model.
    """
    def __init__(self, symbol: str, action: str, confidence: float, meta_data: Dict[str, Any]):
        self.symbol = symbol
        self.action = action  # "BUY", "SELL", "HOLD", "WARMUP"
        self.confidence = confidence
        self.meta_data = meta_data

class MultiAssetPredictor:
    """
    Manages a dictionary of Online Models (one per symbol).
    Performs 'Inference -> Train' loop on every Volume Bar.
    """
    def __init__(self, symbols: List[str]):
        self.symbols = symbols
        self.models_dir = Path("models")
        self.models_dir.mkdir(exist_ok=True)
        
        # 1. State Containers
        self.feature_engineers = {s: OnlineFeatureEngineer(window_size=CONFIG['features']['window_size']) for s in symbols}
        
        # Adaptive Triple Barrier
        tbm_conf = CONFIG['online_learning']['tbm']
        self.labelers = {s: AdaptiveTripleBarrier(
            horizon_ticks=tbm_conf['horizon_minutes'], 
            risk_mult=CONFIG['risk_management']['stop_loss_atr_mult'],
            reward_mult=tbm_conf['barrier_width'], 
            drift_threshold=tbm_conf.get('drift_threshold', 1.0)
        ) for s in symbols}

        # 2. Models (River Ensembles)
        self.models = {}
        self.meta_labelers = {}
        self.calibrators = {}
        
        # 3. Warm-up State
        self.burn_in_counters = {s: 0 for s in symbols}
        self.burn_in_limit = CONFIG['online_learning'].get('burn_in_periods', 1000)
        
        # 4. Forensic Stats
        self.rejection_stats = {s: defaultdict(int) for s in symbols}
        self.feature_stats = {s: defaultdict(float) for s in symbols}
        self.bar_counters = {s: 0 for s in symbols}
        self.feature_importance_counter = {s: Counter() for s in symbols}
        
        # 5. Architecture: Auto-Save Timer
        self.last_save_time = time.time()
        self.save_interval = 300 # 5 Minutes

        # --- Gating Params ---
        self.vol_gate_conf = CONFIG['online_learning'].get('volatility_gate', {})
        self.use_vol_gate = self.vol_gate_conf.get('enabled', True)
        self.min_atr_spread_ratio = self.vol_gate_conf.get('min_atr_spread_ratio', 2.0)
        
        # Regime Gates
        self.min_ker_threshold = CONFIG['microstructure'].get('gate_ker_threshold', 0.10)
        self.fdi_min_random = CONFIG['microstructure'].get('fdi_min_random', 1.48)
        self.fdi_max_random = CONFIG['microstructure'].get('fdi_max_random', 1.52)
        
        self.spread_map = CONFIG.get('forensic_audit', {}).get('spread_pips', {})
        
        # Strategy Specifics
        self.adx_threshold = CONFIG['features']['adx']['threshold']
        self.bb_dev = CONFIG['features']['bollinger_bands']['std_dev']
        
        # Fallback Tracking
        self.l2_missing_warned = {s: False for s in symbols}
        self.last_close_prices = {s: 0.0 for s in symbols}

        # Initialize Models & Load State
        self._init_models()
        self._load_state()

    def _init_models(self):
        """
        Initializes the machine learning pipelines using Golden Config hyperparameters.
        """
        conf = CONFIG['online_learning']
        
        metric_map = {
            "LogLoss": metrics.LogLoss(),
            "F1": metrics.F1(),
            "Accuracy": metrics.Accuracy(),
            "ROCAUC": metrics.ROCAUC()
        }
        selected_metric = metric_map.get(conf.get('metric', 'LogLoss'), metrics.LogLoss())
        
        for sym in self.symbols:
            # Base Classifier: ARF
            base_clf = forest.ARFClassifier(
                n_models=conf['n_models'],
                grace_period=conf['grace_period'],
                delta=conf['delta'],
                split_criterion='gini',
                leaf_prediction='mc',
                max_features=conf.get('max_features', 'log2'),
                lambda_value=conf.get('lambda_value', 10),
                metric=selected_metric,
                warning_detector=drift.ADWIN(delta=conf.get('warning_delta', 0.001)),
                drift_detector=drift.ADWIN(delta=conf['delta'])
            )
            
            # Ensemble Wrapper (Bagging)
            self.models[sym] = compose.Pipeline(
                preprocessing.StandardScaler(),
                ensemble.ADWINBaggingClassifier(
                    model=base_clf,
                    n_models=5, 
                    seed=42
                )
            )
            
            # Meta Model & Calibrator
            self.meta_labelers[sym] = MetaLabeler()
            self.calibrators[sym] = ProbabilityCalibrator()

    def process_bar(self, symbol: str, bar: VolumeBar, context_d1: Dict[str, Any] = None) -> Optional[Signal]:
        """
        Actual entry point called by Engine.
        Executes the Learn-Predict Loop.
        """
        if symbol not in self.symbols: return None
        
        # --- AUTO SAVE CHECK ---
        if time.time() - self.last_save_time > self.save_interval:
            self.save_state()
            self.last_save_time = time.time()

        fe = self.feature_engineers[symbol]
        labeler = self.labelers[symbol]
        model = self.models[symbol]
        meta_labeler = self.meta_labelers[symbol]
        stats = self.rejection_stats[symbol]
        feat_stats = self.feature_stats[symbol]
        
        self.bar_counters[symbol] += 1

        buy_vol = getattr(bar, 'buy_vol', 0.0)
        sell_vol = getattr(bar, 'sell_vol', 0.0)
        
        # --- RETAIL FALLBACK LOGIC ---
        # If L2 data is missing (0.0), estimate using Tick Rule (Price Delta)
        # This prevents the OFI logic from seeing "0.0" and blocking trades.
        if buy_vol == 0 and sell_vol == 0:
            if not self.l2_missing_warned[symbol]:
                logger.warning(f"âš ï¸ {symbol}: Missing L2 Data. Enabling Tick Rule Fallback for OFI.")
                self.l2_missing_warned[symbol] = True
            
            prev_close = self.last_close_prices[symbol]
            if prev_close > 0:
                if bar.close > prev_close:
                    buy_vol = bar.volume
                    sell_vol = 0.0
                elif bar.close < prev_close:
                    buy_vol = 0.0
                    sell_vol = bar.volume
                else:
                    buy_vol = bar.volume / 2
                    sell_vol = bar.volume / 2
            else:
                buy_vol = bar.volume / 2
                sell_vol = bar.volume / 2
                
        self.last_close_prices[symbol] = bar.close
        # -----------------------------

        # 1. Feature Engineering
        features = fe.update(
            price=bar.close,
            timestamp=bar.timestamp,
            volume=bar.volume,
            high=bar.high,
            low=bar.low,
            buy_vol=buy_vol,
            sell_vol=sell_vol
        )
        
        if features is None: return None
        
        if context_d1:
            features = enrich_with_d1_data(features, context_d1, bar.close)

        # Update Feature Stats (Rolling Average for Monitoring)
        alpha = 0.01
        feat_stats['avg_ker'] = (1 - alpha) * feat_stats.get('avg_ker', 0.5) + alpha * features.get('ker', 0.5)
        feat_stats['avg_fdi'] = (1 - alpha) * feat_stats.get('avg_fdi', 1.5) + alpha * features.get('fdi', 1.5)
        
        # New Microstructure Stats
        feat_stats['avg_ofi'] = (1 - alpha) * feat_stats.get('avg_ofi', 0.0) + alpha * features.get('micro_ofi', 0.0)
        
        # --- WARM-UP GATE ---
        if self.burn_in_counters[symbol] < self.burn_in_limit:
            self.burn_in_counters[symbol] += 1
            remaining = self.burn_in_limit - self.burn_in_counters[symbol]
            if remaining % 100 == 0:
                logger.info(f"ðŸ”¥ {symbol} Warm-up: {self.burn_in_counters[symbol]}/{self.burn_in_limit}")
            return Signal(symbol, "WARMUP", 0.0, {"remaining": remaining})

        # 2. Delayed Training (Label Resolution)
        resolved_labels = labeler.resolve_labels(bar.high, bar.low)
        
        if resolved_labels:
            for (stored_feats, outcome_label, realized_ret) in resolved_labels:
                w_pos = CONFIG['online_learning'].get('positive_class_weight', 2.0)
                w_neg = CONFIG['online_learning'].get('negative_class_weight', 2.0)
                
                base_weight = w_pos if outcome_label != 0 else w_neg
                
                # Scale by Profit Magnitude (Log Scale)
                ret_scalar = math.log1p(abs(realized_ret) * 100.0)
                ret_scalar = max(0.5, min(ret_scalar, 5.0))
                final_weight = base_weight * ret_scalar
                
                # Train Primary Model
                model.learn_one(stored_feats, outcome_label, sample_weight=final_weight)
                
                # Double Learn for Positive outcomes (Reinforcement)
                if outcome_label != 0:
                     model.learn_one(stored_feats, outcome_label, sample_weight=final_weight * 1.5)

                # Update Meta-Labeler
                if outcome_label != 0:
                    meta_labeler.update(stored_feats, primary_action=outcome_label, outcome_pnl=realized_ret)

        # 3. Add CURRENT Bar as new Trade Opportunity
        current_atr = features.get('atr', 0.0)
        labeler.add_trade_opportunity(features, bar.close, current_atr, bar.timestamp)

        # ============================================================
        # 4. STRATEGY LOGIC: Regime-Adaptive Mean Reversion
        # ============================================================
        
        adx_val = features.get('adx', 50.0)
        bb_upper = features.get('bb_upper', 999999.0)
        bb_lower = features.get('bb_lower', 0.0)
        micro_ofi = features.get('micro_ofi', 0.0)
        
        proposed_action = 0 # 0=HOLD, 1=BUY, -1=SELL
        rejection_reason = ""
        
        # --- CONDITION 1: REGIME IDENTIFICATION (FILTER) ---
        # Logic: If ADX > 25, Market is Trending -> DISABLE Mean Reversion.
        if adx_val > self.adx_threshold:
            stats[f"Trend Mode (ADX {adx_val:.1f})"] += 1
            # Return HOLD early
            return Signal(symbol, "HOLD", 0.0, {"reason": "Trend Mode"})

        # --- CONDITION 2: THE TRIGGER (BOLLINGER BANDS) ---
        # Short Signal: Price > Upper Band
        if bar.close > bb_upper:
            proposed_action = -1 # Sell
        # Long Signal: Price < Lower Band
        elif bar.close < bb_lower:
            proposed_action = 1 # Buy
        else:
            # Inside bands -> No Trigger
            return Signal(symbol, "HOLD", 0.0, {"reason": "Inside Bands"})

        # --- CONDITION 3: MICROSTRUCTURE CONFIRMATION (OFI) ---
        ofi_threshold = 2.0 # Aggressive flow required
        
        # If we are in Fallback Mode (Tick Rule), reduce threshold because Tick OFI is less granular
        if self.l2_missing_warned[symbol]:
            ofi_threshold = 0.5 

        if proposed_action == -1: # Selling
            if micro_ofi >= -ofi_threshold: # Not enough selling pressure yet
                stats["OFI Wait (Price High, No Sellers)"] += 1
                return Signal(symbol, "HOLD", 0.0, {"reason": "OFI Wait Sell"})
        elif proposed_action == 1: # Buying
            if micro_ofi <= ofi_threshold: # Not enough buying pressure yet
                stats["OFI Wait (Price Low, No Buyers)"] += 1
                return Signal(symbol, "HOLD", 0.0, {"reason": "OFI Wait Buy"})

        # 5. ML Confirmation & Execution
        
        # Primary Prediction (Used for Confidence/Sizing only)
        pred_class = model.predict_one(features)
        pred_proba = model.predict_proba_one(features)
        
        prob_buy = pred_proba.get(1, 0.0)
        prob_sell = pred_proba.get(-1, 0.0)
        
        confidence = prob_buy if proposed_action == 1 else prob_sell
        
        # Meta Labeling
        meta_threshold = CONFIG['online_learning'].get('meta_labeling_threshold', 0.60)
        is_profitable = meta_labeler.predict(
            features,
            proposed_action,
            threshold=meta_threshold
        )

        # --- DECISION ---
        min_conf = CONFIG['online_learning'].get('min_calibrated_probability', 0.85)
        current_ker = features.get('ker', 1.0)
        volatility = features.get('volatility', 0.001)
        frac_diff = features.get('frac_diff', 0.0)
        
        # Safety Check: If ML thinks probability is terrible (< 0.4), skip even if Rule triggers.
        if confidence < 0.40:
            stats["ML Disagreement"] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": "ML Disagreement"})

        if is_profitable:
                action_str = "BUY" if proposed_action == 1 else "SELL"
                
                # FEATURE IMPORTANCE TRACKING
                imp_feats = []
                if adx_val < 25: imp_feats.append('Ranging_Mode')
                if proposed_action == 1: imp_feats.append('BB_Lower_Break')
                else: imp_feats.append('BB_Upper_Break')
                if micro_ofi > 2.0: imp_feats.append('OFI_Strong_Buy')
                elif micro_ofi < -2.0: imp_feats.append('OFI_Strong_Sell')
                
                for f in imp_feats:
                    self.feature_importance_counter[symbol][f] += 1
                
                return Signal(symbol, action_str, confidence, {
                    "meta_ok": True, 
                    "volatility": volatility, 
                    "atr": current_atr, 
                    "ker": current_ker, 
                    "frac_diff": frac_diff,
                    "ofi": micro_ofi,
                    "drivers": imp_feats
                })
        else:
            stats['Meta Rejected'] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": "Meta Rejected"})

        if self.bar_counters[symbol] % 250 == 0:
            top_drivers = self.feature_importance_counter[symbol].most_common(3)
            logger.info(f"ðŸ” {symbol} Stats: KER:{feat_stats['avg_ker']:.2f} FDI:{feat_stats['avg_fdi']:.2f} OFI:{feat_stats['avg_ofi']:.2f} FD:{frac_diff:.4f}")
            logger.info(f"ðŸ” {symbol} Top Drivers: {top_drivers}")
            logger.info(f"ðŸ” {symbol} Rejections: {dict(stats)}")
            stats.clear()
            
        return Signal(symbol, "HOLD", confidence, {})

    def save_state(self):
        """Saves models AND Feature Engineers to disk."""
        try:
            for sym in self.symbols:
                with open(self.models_dir / f"river_pipeline_{sym}.pkl", "wb") as f:
                    pickle.dump(self.models[sym], f)
                with open(self.models_dir / f"meta_model_{sym}.pkl", "wb") as f:
                    pickle.dump(self.meta_labelers[sym], f)
                with open(self.models_dir / f"calibrators_{sym}.pkl", "wb") as f:
                    pickle.dump(self.calibrators[sym], f)
                
                # NEW: Persist Feature Engineer State (FracDiff memory)
                with open(self.models_dir / f"feature_engineer_{sym}.pkl", "wb") as f:
                    pickle.dump(self.feature_engineers[sym], f)
                    
            logger.info(f"{LogSymbols.DATABASE} Models & State Auto-Saved.")
        except Exception as e:
            logger.error(f"{LogSymbols.ERROR} Failed to save models: {e}")

    def _load_state(self):
        """Loads models AND Feature Engineers from disk."""
        loaded_count = 0
        for sym in self.symbols:
            model_path = self.models_dir / f"river_pipeline_{sym}.pkl"
            meta_path = self.models_dir / f"meta_model_{sym}.pkl"
            fe_path = self.models_dir / f"feature_engineer_{sym}.pkl"
            
            if model_path.exists():
                try:
                    with open(model_path, "rb") as f: self.models[sym] = pickle.load(f)
                    loaded_count += 1
                except Exception: pass
            
            if meta_path.exists():
                try:
                    with open(meta_path, "rb") as f: self.meta_labelers[sym] = pickle.load(f)
                except Exception: pass
                
            # NEW: Load Feature Engineer State
            if fe_path.exists():
                try:
                    with open(fe_path, "rb") as f: self.feature_engineers[sym] = pickle.load(f)
                    logger.info(f"Loaded Feature State for {sym}")
                except Exception: pass
                
        if loaded_count > 0:
            logger.info(f"{LogSymbols.SUCCESS} Loaded {loaded_count} existing models.")