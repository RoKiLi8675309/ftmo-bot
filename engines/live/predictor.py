# =============================================================================
# FILENAME: engines/live/predictor.py
# ENVIRONMENT: Linux/WSL2 (Python 3.11)
# PATH: engines/live/predictor.py
# DEPENDENCIES: shared, river, numpy
# DESCRIPTION: Online Learning Kernel. Manages Ensemble Models (Bagging ARF),
# Feature Engineering, Labeling (Adaptive Triple Barrier), and Weighted Learning.
#
# PHOENIX STRATEGY V10.0 (DEFENSIVE PROTOCOL - LIVE):
# 1. LOGIC: Re-enabled D1 Trend Filter (Bias) & RSI Extremes Guard.
# 2. GATES: Stricter KER (0.25) & Anti-Chop (50.0) to filter noise.
# 3. RISK: Per-Symbol Circuit Breaker (Max 2 Losses/Day).
# =============================================================================
import logging
import pickle
import os
import json
import time
import math
import pytz 
from datetime import datetime, date
from collections import defaultdict, deque, Counter
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import numpy as np 

# Third-Party ML Imports
try:
    from river import forest, compose, preprocessing, metrics, drift, linear_model, multioutput, ensemble
except ImportError:
    print("CRITICAL: 'river' library not found. Install with: pip install river>=0.21.0")
    import sys
    sys.exit(1)

# Shared Imports
from shared import (
    CONFIG,
    LogSymbols,
    OnlineFeatureEngineer,
    AdaptiveTripleBarrier,
    ProbabilityCalibrator,
    VolumeBar,
    RiskManager
)

# New Feature Import
from shared.financial.features import MetaLabeler

logger = logging.getLogger("Predictor")

class Signal:
    """
    Represents a trading decision generated by the model.
    """
    def __init__(self, symbol: str, action: str, confidence: float, meta_data: Dict[str, Any]):
        self.symbol = symbol
        self.action = action  # "BUY", "SELL", "HOLD", "WARMUP"
        self.confidence = confidence
        self.meta_data = meta_data

class MultiAssetPredictor:
    """
    Manages a dictionary of Online Models (one per symbol).
    Performs 'Inference -> Train' loop on every Volume Bar.
    """
    def __init__(self, symbols: List[str]):
        self.symbols = symbols
        self.models_dir = Path("models")
        self.models_dir.mkdir(exist_ok=True)
        
        # 1. State Containers
        self.feature_engineers = {s: OnlineFeatureEngineer(window_size=CONFIG['features']['window_size']) for s in symbols}
        
        # 2. Adaptive Triple Barrier (Per-Symbol Dynamic Configuration)
        tbm_conf = CONFIG['online_learning']['tbm']
        risk_conf = CONFIG.get('risk_management', {})
        
        risk_mult_conf = float(risk_conf.get('stop_loss_atr_mult', 2.0))
        
        self.labelers = {}
        self.optimized_params = {} # Cache for gates
        
        # --- V10.0 MOMENTUM INDICATORS ---
        self.bb_window = 20
        self.bb_std = 2.0
        self.bb_buffers = {s: deque(maxlen=self.bb_window) for s in symbols}
        
        for s in symbols:
            # Default from Config
            s_risk = risk_mult_conf
            s_reward = tbm_conf.get('barrier_width', 3.0)
            s_horizon = tbm_conf.get('horizon_minutes', 120)
            
            # --- DYNAMIC PARAMETER LOADING ---
            params_path = self.models_dir / f"best_params_{s}.json"
            if params_path.exists():
                try:
                    with open(params_path, 'r') as f:
                        bp = json.load(f)
                        self.optimized_params[s] = bp 
                        
                        if 'barrier_width' in bp:
                            s_reward = float(bp['barrier_width'])
                        if 'horizon_minutes' in bp:
                            s_horizon = int(bp['horizon_minutes'])
                        
                        if 'risk_per_trade_percent' in bp:
                            if s not in self.optimized_params: self.optimized_params[s] = {}
                            self.optimized_params[s]['risk_per_trade_percent'] = float(bp['risk_per_trade_percent'])
                            
                except Exception as e:
                    logger.warning(f"Failed to load optimized params for {s}: {e}")

            # Initialize Labeler with SPECIFIC params
            self.labelers[s] = AdaptiveTripleBarrier(
                horizon_ticks=s_horizon,
                risk_mult=s_risk,
                reward_mult=s_reward,
                drift_threshold=tbm_conf.get('drift_threshold', 1.5)
            )

        # 3. Models (River Ensembles)
        self.models = {}
        self.meta_labelers = {}
        self.calibrators = {}
        
        # 4. Warm-up State
        self.burn_in_counters = {s: 0 for s in symbols}
        self.burn_in_limit = CONFIG['online_learning'].get('burn_in_periods', 200)
        
        # 5. Forensic Stats
        self.rejection_stats = {s: defaultdict(int) for s in symbols}
        self.feature_stats = {s: defaultdict(float) for s in symbols}
        self.bar_counters = {s: 0 for s in symbols}
        self.feature_importance_counter = {s: Counter() for s in symbols}
        
        # 6. Streak Breaker & Daily Circuit Breaker State
        self.consecutive_losses = {s: 0 for s in symbols}
        self.active_signals = {s: deque() for s in symbols} 
        
        # V10.0: Daily Performance Tracking (Symbol Circuit Breaker)
        # Structure: {symbol: {'date': date_obj, 'losses': int, 'pnl': float}}
        self.daily_performance = {s: {'date': None, 'losses': 0, 'pnl': 0.0} for s in symbols}
        self.daily_max_losses = 2 # Circuit Breaker Limit
        
        # 7. Architecture: Auto-Save Timer
        self.last_save_time = time.time()
        self.save_interval = 300 # 5 Minutes

        # --- Gating Params ---
        self.vol_gate_conf = CONFIG['online_learning'].get('volatility_gate', {})
        self.use_vol_gate = self.vol_gate_conf.get('enabled', True)
        self.min_atr_spread_ratio = self.vol_gate_conf.get('min_atr_spread_ratio', 1.5)
        
        self.spread_map = CONFIG.get('forensic_audit', {}).get('spread_pips', {})
        
        # --- PHOENIX STRATEGY PARAMETERS (V10.0 STRICT) ---
        phx_conf = CONFIG.get('phoenix_strategy', {})
        self.default_max_rvol = 8.0     
        
        # Friday Guard
        self.friday_entry_cutoff = CONFIG['risk_management'].get('friday_entry_cutoff_hour', 16)
        
        # Fallback Tracking
        self.l2_missing_warned = {s: False for s in symbols}
        self.last_close_prices = {s: 0.0 for s in symbols}
        
        # Timezone for Guard
        tz_str = risk_conf.get('risk_timezone', 'Europe/Prague')
        try:
            self.server_tz = pytz.timezone(tz_str)
        except Exception:
            self.server_tz = pytz.timezone('Europe/Prague')

        # --- REC 1: Dynamic Gate Scaling State ---
        self.ker_drift_detectors = {s: drift.ADWIN(delta=0.01) for s in symbols}
        self.dynamic_ker_offsets = {s: 0.0 for s in symbols}

        # --- SNIPER PROTOCOL BUFFERS ---
        self.sniper_closes = {s: deque(maxlen=200) for s in symbols} # For SMA 200
        self.sniper_rsi = {s: deque(maxlen=15) for s in symbols}     # For RSI 14

        # Inject Default Data 
        self._inject_auxiliary_data()

        # Initialize Models & Load State
        self._init_models()
        self._load_state()

    def _init_models(self):
        """
        Initializes the machine learning pipelines.
        """
        conf = CONFIG['online_learning']
        metric_map = {"LogLoss": metrics.LogLoss(), "F1": metrics.F1(), "Accuracy": metrics.Accuracy(), "ROCAUC": metrics.ROCAUC()}
        selected_metric = metric_map.get(conf.get('metric', 'LogLoss'), metrics.LogLoss())
        
        for sym in self.symbols:
            base_clf = forest.ARFClassifier(
                n_models=conf.get('n_models', 50),
                grace_period=conf['grace_period'],
                delta=conf['delta'],
                split_criterion='gini',
                leaf_prediction='mc',
                max_features=conf.get('max_features', 'sqrt'),
                lambda_value=conf.get('lambda_value', 10),
                metric=selected_metric,
                warning_detector=drift.ADWIN(delta=conf.get('warning_delta', 0.001)),
                drift_detector=drift.ADWIN(delta=conf['delta'])
            )
            
            self.models[sym] = compose.Pipeline(
                preprocessing.StandardScaler(),
                ensemble.ADWINBaggingClassifier(model=base_clf, n_models=5, seed=42)
            )
            self.meta_labelers[sym] = MetaLabeler()
            self.calibrators[sym] = ProbabilityCalibrator()

    def process_bar(self, symbol: str, bar: VolumeBar, context_data: Dict[str, Any] = None) -> Optional[Signal]:
        """
        Actual entry point called by Engine.
        Executes the Learn-Predict Loop with Project Phoenix V10.0 Logic.
        """
        if symbol not in self.symbols: return None
        
        # --- AUTO SAVE CHECK ---
        if time.time() - self.last_save_time > self.save_interval:
            self.save_state()
            self.last_save_time = time.time()

        fe = self.feature_engineers[symbol]
        labeler = self.labelers[symbol]
        model = self.models[symbol]
        meta_labeler = self.meta_labelers[symbol]
        stats = self.rejection_stats[symbol]
        feat_stats = self.feature_stats[symbol]
        
        self.bar_counters[symbol] += 1
        self.last_close_prices[symbol] = bar.close

        # --- UPDATE SNIPER BUFFERS ---
        self.sniper_closes[symbol].append(bar.close)
        if len(self.sniper_closes[symbol]) > 1:
            delta = self.sniper_closes[symbol][-1] - self.sniper_closes[symbol][-2]
            self.sniper_rsi[symbol].append(delta)
        self.bb_buffers[symbol].append(bar.close)

        # Extract Flows 
        buy_vol = getattr(bar, 'buy_vol', 0.0)
        sell_vol = getattr(bar, 'sell_vol', 0.0)
        
        # Retail Fallback
        if buy_vol == 0 and sell_vol == 0:
            if not self.l2_missing_warned[symbol]:
                logger.warning(f"âš ï¸ {symbol}: Zero Flow Detected. Using Local Tick Rule Fallback.")
                self.l2_missing_warned[symbol] = True
            
            last_price = self.last_close_prices.get(symbol, bar.close)
            if bar.close > last_price: buy_vol = bar.volume; sell_vol = 0.0
            elif bar.close < last_price: buy_vol = 0.0; sell_vol = bar.volume
            else: buy_vol = bar.volume / 2.0; sell_vol = bar.volume / 2.0
        
        # 1. Feature Engineering
        features = fe.update(
            price=bar.close,
            timestamp=bar.timestamp.timestamp(),
            volume=bar.volume,
            high=bar.high,
            low=bar.low,
            buy_vol=buy_vol,
            sell_vol=sell_vol,
            context_data=context_data
        )
        
        if features is None: return None
        
        # Extract Key Features
        ker_val = features.get('ker', 0.5)
        parkinson = features.get('parkinson_vol', 0.0)

        # --- REC 1: DYNAMIC GATE SCALING ---
        self.ker_drift_detectors[symbol].update(ker_val)
        if self.ker_drift_detectors[symbol].drift_detected:
            self.dynamic_ker_offsets[symbol] = max(-0.10, self.dynamic_ker_offsets[symbol] - 0.05)
        else:
            self.dynamic_ker_offsets[symbol] = min(0.0, self.dynamic_ker_offsets[symbol] + 0.001)

        feat_stats['avg_ker'] = (0.99) * feat_stats.get('avg_ker', 0.5) + 0.01 * features.get('ker', 0.5)
        feat_stats['avg_rvol'] = (0.99) * feat_stats.get('avg_rvol', 1.0) + 0.01 * features.get('rvol', 1.0)
        
        # --- WARM-UP GATE ---
        if self.burn_in_counters[symbol] < self.burn_in_limit:
            self.burn_in_counters[symbol] += 1
            return Signal(symbol, "WARMUP", 0.0, {})

        # --- SERVER TIME & DAILY STATS MANAGEMENT ---
        server_time = bar.timestamp.astimezone(self.server_tz)
        current_date = server_time.date()
        
        # Reset Daily Stats if New Day
        if self.daily_performance[symbol]['date'] != current_date:
            self.daily_performance[symbol] = {'date': current_date, 'losses': 0, 'pnl': 0.0}

        # --- V10.0 CIRCUIT BREAKER (Signal Level) ---
        if self.daily_performance[symbol]['losses'] >= self.daily_max_losses:
            stats["Circuit Breaker (Daily Losses)"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Circuit Breaker Active"})

        # 2. Delayed Training (Label Resolution)
        resolved_labels = labeler.resolve_labels(bar.high, bar.low)
        
        if resolved_labels:
            for (stored_feats, outcome_label, realized_ret) in resolved_labels:
                
                # --- UPDATE PERFORMANCE METRICS ---
                if outcome_label != 0:
                    self.daily_performance[symbol]['pnl'] += realized_ret
                    # Count as loss if realized return is negative (slippage included)
                    if realized_ret < 0:
                        self.daily_performance[symbol]['losses'] += 1
                
                # --- STREAK BREAKER UPDATE ---
                if self.active_signals[symbol]:
                    _ = self.active_signals[symbol].popleft()
                    if outcome_label == 1: self.consecutive_losses[symbol] = 0
                    elif outcome_label == -1: self.consecutive_losses[symbol] += 1

                # --- LEARNING ---
                w_pos = CONFIG['online_learning'].get('positive_class_weight', 1.5)
                w_neg = CONFIG['online_learning'].get('negative_class_weight', 1.0)
                base_weight = w_pos if outcome_label != 0 else w_neg
                
                ret_scalar = math.log1p(abs(realized_ret) * 100.0)
                ret_scalar = max(0.5, min(ret_scalar, 5.0))
                
                hist_ker = stored_feats.get('ker', 0.5)
                ker_weight = hist_ker * 2.0 
                
                final_weight = base_weight * ret_scalar * ker_weight
                
                model.learn_one(stored_feats, outcome_label, sample_weight=final_weight)
                if outcome_label != 0:
                     model.learn_one(stored_feats, outcome_label, sample_weight=final_weight * 1.5)
                if outcome_label != 0:
                    meta_labeler.update(stored_feats, primary_action=outcome_label, outcome_pnl=realized_ret)

        # 3. Add Trade Opportunity
        current_atr = features.get('atr', 0.0)
        features['parkinson_vol'] = parkinson 
        labeler.add_trade_opportunity(features, bar.close, current_atr, bar.timestamp.timestamp(), parkinson_vol=parkinson)

        # ============================================================
        # 4. PHOENIX V10.0: DEFENSIVE GATES
        # ============================================================
        
        rvol = features.get('rvol', 1.0)
        adx_val = features.get('adx', 0.0)
        choppiness = features.get('choppiness', 50.0)
        
        phx = CONFIG.get('phoenix_strategy', {})
        max_rvol_thresh = float(phx.get('max_relative_volume', 8.0)) 
        vol_gate_ratio = float(phx.get('volume_gate_ratio', 1.1)) 
        
        # V10 STRICT THRESHOLDS (Hardcoded Floors)
        chop_threshold = 50.0 # Strict Cap
        
        # FRIDAY GUARD
        if server_time.weekday() == 4 and server_time.hour >= self.friday_entry_cutoff:
             return Signal(symbol, "HOLD", 0.0, {"reason": "Friday Entry Guard"})

        # G1: ANTI-CHOP
        if choppiness > chop_threshold:
            stats[f"Chop Regime (CHOP {choppiness:.1f})"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": f"Chop Regime (CHOP {choppiness:.1f})"})

        # G2: FUEL GAUGE
        if rvol < vol_gate_ratio:
            stats[f"Low Fuel"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Low Fuel"})

        # G3: EXHAUSTION
        if rvol > max_rvol_thresh:
            stats[f"Volume Climax"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Volume Climax"})
            
        # G4: STRICT EFFICIENCY (V10)
        # Ensure KER is at least 0.25 regardless of config or drift
        config_ker = float(phx.get('ker_trend_threshold', 0.10))
        base_thresh = max(0.25, config_ker) # Hard floor at 0.25
        effective_ker_thresh = max(0.25, base_thresh + self.dynamic_ker_offsets[symbol])

        if ker_val < effective_ker_thresh:
            stats[f"Low Efficiency"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": f"Low Efficiency (KER {ker_val:.2f} < {effective_ker_thresh:.2f})"})

        # G5: TREND STRENGTH
        if adx_val < 20.0:
            stats[f"Weak Trend"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": f"Weak Trend (ADX {adx_val:.1f})"})

        # --- MTF TREND CONTEXT (V10 ENABLED) ---
        d1_ema = context_data.get('d1', {}).get('ema200', 0.0) if context_data else 0.0
        
        proposed_action = 0
        regime_label = "Chop"

        # --- MOMENTUM BREAKOUT TRIGGER ---
        if len(self.bb_buffers[symbol]) < self.bb_window:
            stats["Warming Up BB"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Warming Up BB"})
            
        bb_mu = np.mean(self.bb_buffers[symbol])
        bb_std = np.std(self.bb_buffers[symbol])
        upper_bb = bb_mu + (self.bb_std * bb_std)
        lower_bb = bb_mu - (self.bb_std * bb_std)
        
        rsi_val = features.get('rsi_norm', 0.5) * 100.0
        
        trigger_bull = (bar.close > upper_bb) and (rsi_val > 50)
        trigger_bear = (bar.close < lower_bb) and (rsi_val < 50)

        if trigger_bull:
            proposed_action = 1
            regime_label = "Breakout-Long"
        elif trigger_bear:
            proposed_action = -1
            regime_label = "Breakout-Short"
        else:
            stats["No Breakout"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "No Breakout"})

        # 5. ML Confirmation
        pred_proba = model.predict_proba_one(features)
        prob_buy = pred_proba.get(1, 0.0)
        prob_sell = pred_proba.get(-1, 0.0)
        confidence = prob_buy if proposed_action == 1 else prob_sell
        
        meta_threshold = CONFIG['online_learning'].get('meta_labeling_threshold', 0.60) # V10 Strict
        is_profitable = meta_labeler.predict(features, proposed_action, threshold=meta_threshold)

        # --- EXECUTION WITH DYNAMIC CONFIDENCE (V10 Strict) ---
        min_prob = CONFIG['online_learning'].get('min_calibrated_probability', 0.60)
        
        if confidence < min_prob:
            stats[f"ML Disagreement"] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": f"ML Disagreement (Conf < {min_prob:.2f})"})

        # --- SNIPER PROTOCOL: FINAL FILTER GATE (V10) ---
        # Checks D1 Trend Bias & RSI Extremes
        if not self._check_sniper_filters(symbol, proposed_action, bar.close, d1_ema):
            stats["Sniper Reject (Trend/RSI)"] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": "Sniper Filter Reject"})
        # ------------------------------------------

        if is_profitable:
                action_str = "BUY" if proposed_action == 1 else "SELL"
                self.active_signals[symbol].append(action_str)
                
                imp_feats = []
                imp_feats.append(regime_label)
                if rvol > 2.0: imp_feats.append('High_Fuel')
                
                for f in imp_feats:
                    self.feature_importance_counter[symbol][f] += 1
                
                opt_rr = self.labelers[symbol].reward_mult
                opt_risk = self.optimized_params.get(symbol, {}).get('risk_per_trade_percent')

                return Signal(symbol, action_str, confidence, {
                    "meta_ok": True,
                    "volatility": features.get('volatility', 0.001),
                    "atr": current_atr,
                    "ker": ker_val,
                    "parkinson_vol": parkinson,
                    "rvol": rvol,
                    "amihud": features.get('amihud', 0.0),
                    "choppiness": choppiness,
                    "regime": regime_label,
                    "drivers": imp_feats,
                    "optimized_rr": opt_rr,
                    "risk_percent_override": opt_risk,
                    "pyramid": False
                })
        else:
            stats['Meta Rejected'] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": "Meta Rejected"})

        if self.bar_counters[symbol] % 250 == 0:
            logger.info(f"ðŸ” {symbol} Stats: KER:{feat_stats['avg_ker']:.2f} Streak:{self.consecutive_losses[symbol]}")
            logger.info(f"ðŸ” {symbol} Rejections: {dict(stats)}")
            stats.clear()
            
        return Signal(symbol, "HOLD", confidence, {})

    def _check_sniper_filters(self, symbol: str, signal: int, price: float, d1_ema: float) -> bool:
        """
        V10.0 SNIPER PROTOCOL (LIVE):
        1. Trend Filter: Trade ONLY if price aligns with D1 EMA 200 (if available).
        2. RSI Guard: Strict Overbought (70) / Oversold (30) rejection.
        """
        closes = self.sniper_closes[symbol]
        rsi_buf = self.sniper_rsi[symbol]
        
        if len(closes) < 200:
            return True # Not enough data, default to allow

        # 1. Calculate Simple RSI (Approximate for speed)
        gains = [x for x in rsi_buf if x > 0]
        losses = [abs(x) for x in rsi_buf if x < 0]
        avg_gain = sum(gains) / 14 if gains else 0
        avg_loss = sum(losses) / 14 if losses else 1e-9
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))

        # 2. TREND FILTER (D1 Bias)
        trend_aligned = False
        if d1_ema > 0: # If context available
            if signal == 1: # BUY
                if price > d1_ema: trend_aligned = True
                else: return False # Reject Counter-Trend
            elif signal == -1: # SELL
                if price < d1_ema: trend_aligned = True
                else: return False # Reject Counter-Trend
        else:
            trend_aligned = True # Pass if no D1 data (fallback)

        # 3. RSI EXTREME GUARD
        if signal == 1: # BUY
            if rsi > 70: return False # Reject Overbought
        elif signal == -1: # SELL
            if rsi < 30: return False # Reject Oversold
                
        return True

    def _inject_auxiliary_data(self):
        """Injects static approximations ONLY if missing."""
        defaults = {
            "USDJPY": 150.0, "GBPUSD": 1.25, "EURUSD": 1.08,
            "USDCAD": 1.35, "USDCHF": 0.90, "AUDUSD": 0.65, "NZDUSD": 0.60,
            "GBPJPY": 190.0, "EURJPY": 160.0, "AUDJPY": 95.0
        }
        for sym, price in defaults.items():
            if sym not in self.last_close_prices or self.last_close_prices[sym] == 0:
                self.last_close_prices[sym] = price

    def save_state(self):
        """Saves models AND Feature Engineers to disk."""
        try:
            for sym in self.symbols:
                with open(self.models_dir / f"river_pipeline_{sym}.pkl", "wb") as f:
                    pickle.dump(self.models[sym], f)
                with open(self.models_dir / f"meta_model_{sym}.pkl", "wb") as f:
                    pickle.dump(self.meta_labelers[sym], f)
                with open(self.models_dir / f"calibrators_{sym}.pkl", "wb") as f:
                    pickle.dump(self.calibrators[sym], f)
                
                with open(self.models_dir / f"feature_engineer_{sym}.pkl", "wb") as f:
                    pickle.dump(self.feature_engineers[sym], f)
                    
            logger.info(f"{LogSymbols.DATABASE} Models & State Auto-Saved.")
        except Exception as e:
            logger.error(f"{LogSymbols.ERROR} Failed to save models: {e}")

    def _load_state(self):
        """Loads models AND Feature Engineers from disk."""
        loaded_count = 0
        for sym in self.symbols:
            model_path = self.models_dir / f"river_pipeline_{sym}.pkl"
            meta_path = self.models_dir / f"meta_model_{sym}.pkl"
            fe_path = self.models_dir / f"feature_engineer_{sym}.pkl"
            
            if model_path.exists():
                try:
                    with open(model_path, "rb") as f: self.models[sym] = pickle.load(f)
                    loaded_count += 1
                except Exception: pass
            
            if meta_path.exists():
                try:
                    with open(meta_path, "rb") as f: self.meta_labelers[sym] = pickle.load(f)
                except Exception: pass
            
            if fe_path.exists():
                try:
                    with open(fe_path, "rb") as f: self.feature_engineers[sym] = pickle.load(f)
                    logger.info(f"Loaded Feature State for {sym}")
                except Exception: pass
            
        if loaded_count > 0:
            logger.info(f"{LogSymbols.SUCCESS} Loaded {loaded_count} existing models.")