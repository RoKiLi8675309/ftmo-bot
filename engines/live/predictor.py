# =============================================================================
# FILENAME: engines/live/predictor.py
# ENVIRONMENT: Linux/WSL2 (Python 3.11)
# PATH: engines/live/predictor.py
# DEPENDENCIES: shared, river, numpy
# DESCRIPTION: Online Learning Kernel. Manages Ensemble Models (Bagging ARF),
# Feature Engineering, Labeling (Adaptive Triple Barrier), and Weighted Learning.
#
# AUDIT REMEDIATION (2025-12-31 - RISK OPTIMIZATION & CONFIG):
# 1. RISK LOADING: Loads 'risk_per_trade_percent' from optimized params file.
# 2. SIGNAL INJECTION: Passes optimized risk to Live Engine via Signal metadata.
# 3. STREAK BREAKER: Retained logic for dynamic gate tightening.
# =============================================================================
import logging
import pickle
import os
import json
import time
import math
from collections import defaultdict, deque, Counter
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

# Third-Party ML Imports
try:
    from river import forest, compose, preprocessing, metrics, drift, linear_model, multioutput, ensemble
except ImportError:
    print("CRITICAL: 'river' library not found. Install with: pip install river>=0.21.0")
    import sys
    sys.exit(1)

# Shared Imports
from shared import (
    CONFIG,
    LogSymbols,
    OnlineFeatureEngineer,
    AdaptiveTripleBarrier,
    ProbabilityCalibrator,
    VolumeBar,
    RiskManager
)

# New Feature Import
from shared.financial.features import MetaLabeler

logger = logging.getLogger("Predictor")

class Signal:
    """
    Represents a trading decision generated by the model.
    """
    def __init__(self, symbol: str, action: str, confidence: float, meta_data: Dict[str, Any]):
        self.symbol = symbol
        self.action = action  # "BUY", "SELL", "HOLD", "WARMUP"
        self.confidence = confidence
        self.meta_data = meta_data

class MultiAssetPredictor:
    """
    Manages a dictionary of Online Models (one per symbol).
    Performs 'Inference -> Train' loop on every Volume Bar.
    """
    def __init__(self, symbols: List[str]):
        self.symbols = symbols
        self.models_dir = Path("models")
        self.models_dir.mkdir(exist_ok=True)
        
        # 1. State Containers
        self.feature_engineers = {s: OnlineFeatureEngineer(window_size=CONFIG['features']['window_size']) for s in symbols}
        
        # 2. Adaptive Triple Barrier (Per-Symbol Dynamic Configuration)
        tbm_conf = CONFIG['online_learning']['tbm']
        risk_mult_conf = CONFIG['risk_management'].get('stop_loss_atr_mult', 1.5)
        
        self.labelers = {}
        self.optimized_params = {} # Cache for gates
        
        for s in symbols:
            # Default from Config
            s_risk = risk_mult_conf
            s_reward = tbm_conf.get('barrier_width', 3.0)
            s_horizon = tbm_conf.get('horizon_minutes', 120)
            
            # --- DYNAMIC PARAMETER LOADING ---
            # Try to load optimized R:R and Risk from Research
            params_path = self.models_dir / f"best_params_{s}.json"
            if params_path.exists():
                try:
                    with open(params_path, 'r') as f:
                        bp = json.load(f)
                        self.optimized_params[s] = bp # Store for gate logic
                        
                        # Optuna stores this as a flat key if suggested via suggest_float
                        if 'barrier_width' in bp:
                            s_reward = float(bp['barrier_width'])
                        if 'horizon_minutes' in bp:
                            s_horizon = int(bp['horizon_minutes'])
                        
                        # NEW: Load Risk Param
                        if 'risk_per_trade_percent' in bp:
                            # Store in dict to ensure persistence
                            if s not in self.optimized_params: self.optimized_params[s] = {}
                            self.optimized_params[s]['risk_per_trade_percent'] = float(bp['risk_per_trade_percent'])
                            
                    # logger.info(f"âš¡ {s}: Loaded Optimized Params (TP: {s_reward} ATR)")
                except Exception as e:
                    logger.warning(f"Failed to load optimized params for {s}: {e}")

            # Initialize Labeler with SPECIFIC params
            self.labelers[s] = AdaptiveTripleBarrier(
                horizon_ticks=s_horizon,
                risk_mult=s_risk,
                reward_mult=s_reward,
                drift_threshold=tbm_conf.get('drift_threshold', 1.5)
            )

        # 3. Models (River Ensembles)
        self.models = {}
        self.meta_labelers = {}
        self.calibrators = {}
        
        # 4. Warm-up State
        self.burn_in_counters = {s: 0 for s in symbols}
        self.burn_in_limit = CONFIG['online_learning'].get('burn_in_periods', 200) 
        
        # 5. Forensic Stats
        self.rejection_stats = {s: defaultdict(int) for s in symbols}
        self.feature_stats = {s: defaultdict(float) for s in symbols}
        self.bar_counters = {s: 0 for s in symbols}
        self.feature_importance_counter = {s: Counter() for s in symbols}
        
        # 6. Streak Breaker State (Internal Tracking)
        self.consecutive_losses = {s: 0 for s in symbols}
        self.active_signals = {s: deque() for s in symbols} # Track issued signals to match outcomes
        
        # 7. Architecture: Auto-Save Timer
        self.last_save_time = time.time()
        self.save_interval = 300 # 5 Minutes

        # --- Gating Params ---
        self.vol_gate_conf = CONFIG['online_learning'].get('volatility_gate', {})
        self.use_vol_gate = self.vol_gate_conf.get('enabled', True)
        self.min_atr_spread_ratio = self.vol_gate_conf.get('min_atr_spread_ratio', 1.5)
        
        self.spread_map = CONFIG.get('forensic_audit', {}).get('spread_pips', {})
        
        # --- PHOENIX STRATEGY PARAMETERS (DEFAULTS) ---
        phx_conf = CONFIG.get('phoenix_strategy', {})
        self.default_ker_thresh = phx_conf.get('ker_trend_threshold', 0.35)
        self.default_max_rvol = phx_conf.get('max_relative_volume', 4.0)
        
        # Friday Guard
        self.friday_entry_cutoff = CONFIG['risk_management'].get('friday_entry_cutoff_hour', 16)
        
        # Fallback Tracking
        self.l2_missing_warned = {s: False for s in symbols}
        self.last_close_prices = {s: 0.0 for s in symbols}

        # Inject Default Data for JPY Basket (Prevents Risk Manager Zeros)
        self._inject_auxiliary_data()

        # Initialize Models & Load State
        self._init_models()
        self._load_state()

    def _init_models(self):
        """
        Initializes the machine learning pipelines using Golden Config hyperparameters.
        """
        conf = CONFIG['online_learning']
        
        metric_map = {
            "LogLoss": metrics.LogLoss(),
            "F1": metrics.F1(),
            "Accuracy": metrics.Accuracy(),
            "ROCAUC": metrics.ROCAUC()
        }
        selected_metric = metric_map.get(conf.get('metric', 'LogLoss'), metrics.LogLoss())
        
        for sym in self.symbols:
            # Base Classifier: ARF
            base_clf = forest.ARFClassifier(
                n_models=conf.get('n_models', 50),
                grace_period=conf['grace_period'],
                delta=conf['delta'],
                split_criterion='gini',
                leaf_prediction='mc',
                max_features=conf.get('max_features', 'sqrt'),
                lambda_value=conf.get('lambda_value', 10),
                metric=selected_metric,
                warning_detector=drift.ADWIN(delta=conf.get('warning_delta', 0.001)),
                drift_detector=drift.ADWIN(delta=conf['delta'])
            )
            
            # Ensemble Wrapper (Bagging)
            self.models[sym] = compose.Pipeline(
                preprocessing.StandardScaler(),
                ensemble.ADWINBaggingClassifier(
                    model=base_clf,
                    n_models=5, 
                    seed=42
                )
            )
            
            # Meta Model & Calibrator
            self.meta_labelers[sym] = MetaLabeler()
            self.calibrators[sym] = ProbabilityCalibrator()

    def process_bar(self, symbol: str, bar: VolumeBar, context_data: Dict[str, Any] = None) -> Optional[Signal]:
        """
        Actual entry point called by Engine.
        Executes the Learn-Predict Loop with Project Phoenix V5.0 Logic.
        """
        if symbol not in self.symbols: return None
        
        # --- AUTO SAVE CHECK ---
        if time.time() - self.last_save_time > self.save_interval:
            self.save_state()
            self.last_save_time = time.time()

        fe = self.feature_engineers[symbol]
        labeler = self.labelers[symbol]
        model = self.models[symbol]
        meta_labeler = self.meta_labelers[symbol]
        stats = self.rejection_stats[symbol]
        feat_stats = self.feature_stats[symbol]
        
        self.bar_counters[symbol] += 1
        
        # Ensure we have a price for risk calculations (Live update)
        self.last_close_prices[symbol] = bar.close

        # Extract Flows (Populated by Aggregator in shared/data.py)
        buy_vol = getattr(bar, 'buy_vol', 0.0)
        sell_vol = getattr(bar, 'sell_vol', 0.0)
        
        # --- RETAIL FALLBACK ---
        if buy_vol == 0 and sell_vol == 0:
            if not self.l2_missing_warned[symbol]:
                logger.warning(f"âš ï¸ {symbol}: Zero Flow Detected. Using Local Tick Rule Fallback.")
                self.l2_missing_warned[symbol] = True
            
            last_price = self.last_close_prices.get(symbol, bar.close) 
            if bar.close > last_price:
                buy_vol = bar.volume; sell_vol = 0.0
            elif bar.close < last_price:
                buy_vol = 0.0; sell_vol = bar.volume
            else:
                buy_vol = bar.volume / 2.0; sell_vol = bar.volume / 2.0
        
        # 1. Feature Engineering (Digesting D1/H4 Context)
        features = fe.update(
            price=bar.close,
            timestamp=bar.timestamp.timestamp(),
            volume=bar.volume,
            high=bar.high,
            low=bar.low,
            buy_vol=buy_vol,
            sell_vol=sell_vol,
            context_data=context_data 
        )
        
        if features is None: return None
        
        # Update Feature Stats
        alpha = 0.01
        feat_stats['avg_ker'] = (1 - alpha) * feat_stats.get('avg_ker', 0.5) + alpha * features.get('ker', 0.5)
        feat_stats['avg_rvol'] = (1 - alpha) * feat_stats.get('avg_rvol', 1.0) + alpha * features.get('rvol', 1.0)
        
        # --- WARM-UP GATE ---
        if self.burn_in_counters[symbol] < self.burn_in_limit:
            self.burn_in_counters[symbol] += 1
            return Signal(symbol, "WARMUP", 0.0, {})

        # 2. Delayed Training (Label Resolution) & Streak Update
        resolved_labels = labeler.resolve_labels(bar.high, bar.low)
        
        if resolved_labels:
            for (stored_feats, outcome_label, realized_ret) in resolved_labels:
                
                # --- STREAK BREAKER UPDATE ---
                # Check if this resolved label corresponds to a trade we signaled
                # Outcome_label: 1=Win(Target), -1=Loss(Stop), 0=Neutral
                # Note: This is an internal proxy. Real PnL comes from Engine, but this ensures autonomy.
                if self.active_signals[symbol]:
                    # Simple FIFO matching for now
                    # (In a complex system, we'd match IDs, but barriers are sequential)
                    _ = self.active_signals[symbol].popleft()
                    
                    if outcome_label == 1:
                        self.consecutive_losses[symbol] = 0 # WIN -> Reset Streak
                    elif outcome_label == -1:
                        self.consecutive_losses[symbol] += 1 # LOSS -> Increment Streak
                    # Ignore 0 (Time expiry usually scratch)

                # --- LEARNING ---
                w_pos = CONFIG['online_learning'].get('positive_class_weight', 1.5)
                w_neg = CONFIG['online_learning'].get('negative_class_weight', 1.0)
                
                base_weight = w_pos if outcome_label != 0 else w_neg
                
                # Scale by Profit Magnitude (Log Scale)
                ret_scalar = math.log1p(abs(realized_ret) * 100.0)
                ret_scalar = max(0.5, min(ret_scalar, 5.0))
                final_weight = base_weight * ret_scalar
                
                # Train Primary Model
                model.learn_one(stored_feats, outcome_label, sample_weight=final_weight)
                
                # Double Learn for Positive outcomes
                if outcome_label != 0:
                     model.learn_one(stored_feats, outcome_label, sample_weight=final_weight * 1.5)

                # Update Meta-Labeler
                if outcome_label != 0:
                    meta_labeler.update(stored_feats, primary_action=outcome_label, outcome_pnl=realized_ret)

        # 3. Add CURRENT Bar as new Trade Opportunity
        current_atr = features.get('atr', 0.0)
        labeler.add_trade_opportunity(features, bar.close, current_atr, bar.timestamp.timestamp())

        # ============================================================
        # 4. PHOENIX STRATEGY LOGIC: GATES & REGIMES (V5.0 SIMPLE)
        # ============================================================
        
        # Extract Core Indicators
        rvol = features.get('rvol', 1.0)
        ker_val = features.get('ker', 0.5)
        aggressor = features.get('aggressor', 0.5)
        amihud = features.get('amihud', 0.0)
        atr_val = features.get('atr', 0.0001)
        parkinson = features.get('parkinson_vol', 0.0)
        mtf_align = features.get('mtf_alignment', 0.0)
        adx_val = features.get('adx', 0.0)
        
        # Retrieve Optimized or Default Params
        opt = self.optimized_params.get(symbol, {})
        max_rvol_thresh = self.default_max_rvol
        ker_thresh = self.default_ker_thresh
        
        # --- FRIDAY GUARD ---
        if bar.timestamp.weekday() == 4 and bar.timestamp.hour >= self.friday_entry_cutoff:
             stats["Friday Entry Guard"] += 1
             return Signal(symbol, "HOLD", 0.0, {"reason": "Friday Entry Guard"})

        # --- CRITICAL FILTER 1: VOLUME EXHAUSTION FILTER ---
        if rvol > max_rvol_thresh:
            stats[f"Volume Climax"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Volume Climax"})
            
        # --- STREAK BREAKER: DYNAMIC EFFICIENCY GATE ---
        # If we are in a losing streak, require higher efficiency (cleaner trends)
        streak = self.consecutive_losses[symbol]
        effective_ker_thresh = ker_thresh
        
        if streak > 0:
            # Add 0.05 per loss, cap at +0.25
            effective_ker_thresh += min(0.25, streak * 0.05)
            
        if ker_val < effective_ker_thresh:
            stats[f"Low Efficiency (Streak: {streak})"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": f"Low Efficiency (Streak: {streak})"})

        # --- CRITICAL FILTER 2: MTF TREND LOCK ---
        d1_ema = context_data.get('d1', {}).get('ema200', 0.0) if context_data else 0.0
        d1_trend_up = (bar.close > d1_ema) if d1_ema > 0 else True
        d1_trend_down = (bar.close < d1_ema) if d1_ema > 0 else True
        
        # --- NEW: H4 RSI ALIGNMENT ---
        h4_rsi = context_data.get('h4', {}).get('rsi', 50.0) if context_data else 50.0
        h4_bull = h4_rsi > 50
        h4_bear = h4_rsi < 50
        
        phx_conf = CONFIG.get('phoenix_strategy', {})
        enable_regime_a = phx_conf.get('enable_regime_a_entries', True)
        require_d1_trend = phx_conf.get('require_d1_trend', True)
        require_h4_alignment = phx_conf.get('require_h4_alignment', True)
        vol_gate_ratio = phx_conf.get('volume_gate_ratio', 1.1)
        aggressor_thresh = phx_conf.get('aggressor_threshold', 0.55)
        
        # Gate Definitions
        vol_gate = rvol > vol_gate_ratio
        
        # Momentum Direction
        is_bullish_candle = aggressor > aggressor_thresh
        is_bearish_candle = aggressor < (1.0 - aggressor_thresh)
        
        proposed_action = 0 
        regime_label = "C (Noise)"

        # --- REGIME A: MOMENTUM IGNITION ---
        if enable_regime_a:
            if d1_trend_up and is_bullish_candle and vol_gate:
                proposed_action = 1
                regime_label = "A (Mom-Long)"
            
            elif d1_trend_down and is_bearish_candle and vol_gate:
                proposed_action = -1
                regime_label = "A (Mom-Short)"

            elif (d1_trend_up and is_bullish_candle) or (d1_trend_down and is_bearish_candle):
                if not vol_gate:
                    stats[f"Volume Gate Fail"] += 1
                
        # --- REGIME B: EFFICIENT TREND CONTINUATION ---
        is_trending = adx_val > CONFIG['features']['adx'].get('threshold', 18)
        
        if proposed_action == 0 and vol_gate:
            if not is_trending:
                stats[f"Regime B: Low ADX"] += 1
            else:
                if is_bullish_candle and d1_trend_up:
                    if require_h4_alignment and not h4_bull:
                        stats["Regime B: H4 Mismatch"] += 1
                    else:
                        proposed_action = 1
                        regime_label = "B (Trend-Long)"
                elif is_bearish_candle and d1_trend_down:
                    if require_h4_alignment and not h4_bear:
                        stats["Regime B: H4 Mismatch"] += 1
                    else:
                        proposed_action = -1
                        regime_label = "B (Trend-Short)"
                else:
                    stats["Regime B: Counter Trend"] += 1
        
        # --- REGIME C: NOISE ---
        if proposed_action == 0:
            regime_label = "C (Noise)"
            stats[f"No Signal Condition"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Regime C (Noise)"})

        # --- FINAL MTF SAFETY CHECK ---
        if proposed_action == 1 and not d1_trend_up and require_d1_trend:
            stats[f"MTF Lock"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "MTF Lock"})
        if proposed_action == -1 and not d1_trend_down and require_d1_trend:
            stats[f"MTF Lock"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "MTF Lock"})

        # ---------------------------------------------------------------------
        # MEAN REVERSION FILTER (Safety Check)
        # ---------------------------------------------------------------------
        bb_pos = features.get('bb_position', 0.5)
        rsi_val = features.get('rsi_norm', 0.5) * 100.0
        
        if proposed_action == -1: # SELL
            if bb_pos < 0.0 or rsi_val < 30:
                stats[f"Mean Rev Filter"] += 1
                return Signal(symbol, "HOLD", 0.0, {"reason": "Mean Rev Filter"})
        elif proposed_action == 1: # BUY
            if bb_pos > 1.0 or rsi_val > 70:
                stats[f"Mean Rev Filter"] += 1
                return Signal(symbol, "HOLD", 0.0, {"reason": "Mean Rev Filter"})

        # 5. ML Confirmation & Execution
        pred_proba = model.predict_proba_one(features)
        prob_buy = pred_proba.get(1, 0.0)
        prob_sell = pred_proba.get(-1, 0.0)
        
        confidence = prob_buy if proposed_action == 1 else prob_sell
        
        # Meta Labeling
        meta_threshold = CONFIG['online_learning'].get('meta_labeling_threshold', 0.55)
        is_profitable = meta_labeler.predict(
            features, 
            proposed_action, 
            threshold=meta_threshold
        )

        # --- DECISION WITH DYNAMIC CONFIDENCE ---
        min_prob = CONFIG['online_learning'].get('min_calibrated_probability', 0.60)
        
        # STREAK BREAKER: Increase required confidence
        if streak > 0:
            min_prob += min(0.15, streak * 0.05)

        if confidence < min_prob:
            stats[f"ML Disagreement (Streak: {streak})"] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": f"ML Disagreement (Conf < {min_prob:.2f})"})

        if is_profitable:
                action_str = "BUY" if proposed_action == 1 else "SELL"
                
                # Register Signal for Streak Tracking
                self.active_signals[symbol].append(action_str) 
                
                # FEATURE IMPORTANCE TRACKING
                imp_feats = []
                imp_feats.append(regime_label)
                if rvol > 1.2: imp_feats.append('High_Volume')
                if parkinson > 0.002: imp_feats.append('High_Parkinson')
                if mtf_align == 1.0: imp_feats.append('MTF_Aligned')
                
                for f in imp_feats:
                    self.feature_importance_counter[symbol][f] += 1
                
                # Retrieve optimized R:R for metadata
                opt_rr = self.labelers[symbol].reward_mult
                opt_risk = self.optimized_params.get(symbol, {}).get('risk_per_trade_percent')

                return Signal(symbol, action_str, confidence, {
                    "meta_ok": True, 
                    "volatility": features.get('volatility', 0.001), 
                    "atr": current_atr, 
                    "ker": ker_val, 
                    "parkinson_vol": parkinson, 
                    "rvol": rvol,
                    "amihud": amihud,
                    "regime": regime_label,
                    "mtf_align": mtf_align,
                    "drivers": imp_feats,
                    "optimized_rr": opt_rr,
                    "risk_percent_override": opt_risk
                })
        else:
            stats['Meta Rejected'] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": "Meta Rejected"})

        # Periodic Stats Logging
        if self.bar_counters[symbol] % 250 == 0:
            top_drivers = self.feature_importance_counter[symbol].most_common(3)
            logger.info(f"ðŸ” {symbol} Stats: KER:{feat_stats['avg_ker']:.2f} RVol:{feat_stats['avg_rvol']:.2f} Streak:{self.consecutive_losses[symbol]}")
            logger.info(f"ðŸ” {symbol} Rejections: {dict(stats)}")
            stats.clear()
            
        return Signal(symbol, "HOLD", confidence, {})

    def _inject_auxiliary_data(self):
        """Injects static approximations ONLY if missing."""
        defaults = {
            "USDJPY": 150.0, "GBPUSD": 1.25, "EURUSD": 1.08,
            "USDCAD": 1.35, "USDCHF": 0.90, "AUDUSD": 0.65, "NZDUSD": 0.60,
            "GBPJPY": 190.0, "EURJPY": 160.0, "AUDJPY": 95.0 # JPY Basket
        }
        for sym, price in defaults.items():
            if sym not in self.last_close_prices or self.last_close_prices[sym] == 0:
                self.last_close_prices[sym] = price

    def save_state(self):
        """Saves models AND Feature Engineers to disk."""
        try:
            for sym in self.symbols:
                with open(self.models_dir / f"river_pipeline_{sym}.pkl", "wb") as f:
                    pickle.dump(self.models[sym], f)
                with open(self.models_dir / f"meta_model_{sym}.pkl", "wb") as f:
                    pickle.dump(self.meta_labelers[sym], f)
                with open(self.models_dir / f"calibrators_{sym}.pkl", "wb") as f:
                    pickle.dump(self.calibrators[sym], f)
                
                # Persist Feature Engineer State
                with open(self.models_dir / f"feature_engineer_{sym}.pkl", "wb") as f:
                    pickle.dump(self.feature_engineers[sym], f)
                    
            logger.info(f"{LogSymbols.DATABASE} Models & State Auto-Saved.")
        except Exception as e:
            logger.error(f"{LogSymbols.ERROR} Failed to save models: {e}")

    def _load_state(self):
        """Loads models AND Feature Engineers from disk."""
        loaded_count = 0
        for sym in self.symbols:
            model_path = self.models_dir / f"river_pipeline_{sym}.pkl"
            meta_path = self.models_dir / f"meta_model_{sym}.pkl"
            fe_path = self.models_dir / f"feature_engineer_{sym}.pkl"
            
            if model_path.exists():
                try:
                    with open(model_path, "rb") as f: self.models[sym] = pickle.load(f)
                    loaded_count += 1
                except Exception: pass
            
            if meta_path.exists():
                try:
                    with open(meta_path, "rb") as f: self.meta_labelers[sym] = pickle.load(f)
                except Exception: pass
                
            if fe_path.exists():
                try:
                    with open(fe_path, "rb") as f: self.feature_engineers[sym] = pickle.load(f)
                    logger.info(f"Loaded Feature State for {sym}")
                except Exception: pass
                
        if loaded_count > 0:
            logger.info(f"{LogSymbols.SUCCESS} Loaded {loaded_count} existing models.")