# =============================================================================
# FILENAME: engines/live/predictor.py
# ENVIRONMENT: Linux/WSL2 (Python 3.11)
# PATH: engines/live/predictor.py
# DEPENDENCIES: shared, river, numpy, pandas
# DESCRIPTION: Online Learning Kernel. Manages Ensemble Models (Bagging ARF),
# Feature Engineering (Golden Trio), Labeling (Adaptive Triple Barrier).
#
# PHOENIX V16.20 AUDIT FIX (THE HALLUCINATOR CURE):
# 1. GAP BRIDGING: First live bar after warmup is used ONLY for state alignment,
#    preventing "Gap Return" shocks from triggering false breakout signals.
# 2. STATE SEPARATION: Strict reset of price references between History and Live.
# 3. PYRAMID GUARD: Reinforced "Profit Gate" to prevent adding to losers.
# =============================================================================
import logging
import pickle
import os
import json
import time
import math
import pytz 
from datetime import datetime, date
from collections import defaultdict, deque, Counter
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import numpy as np 
import pandas as pd

# Third-Party ML Imports
try:
    from river import forest, compose, preprocessing, metrics, drift, multioutput, ensemble
except ImportError:
    print("CRITICAL: 'river' library not found. Install with: pip install river>=0.21.0")
    import sys
    sys.exit(1)

# Shared Imports
from shared import (
    CONFIG,
    LogSymbols,
    OnlineFeatureEngineer,
    AdaptiveTripleBarrier,
    ProbabilityCalibrator,
    VolumeBar,
    RiskManager,
    load_real_data,             # Required for Warm-up
    AdaptiveImbalanceBarGenerator # Required for Warm-up
)

# New Feature Import
from shared.financial.features import MetaLabeler

logger = logging.getLogger("Predictor")

class Signal:
    """
    Represents a trading decision generated by the model.
    """
    def __init__(self, symbol: str, action: str, confidence: float, meta_data: Dict[str, Any]):
        self.symbol = symbol
        self.action = action  # "BUY", "SELL", "HOLD", "WARMUP"
        self.confidence = confidence
        self.meta_data = meta_data

class MultiAssetPredictor:
    """
    Manages a dictionary of Online Models (one per symbol).
    Performs 'Inference -> Train' loop on every Volume Bar.
    """
    def __init__(self, symbols: List[str], threshold_map: Optional[Dict[str, float]] = None):
        """
        V16.7 UPDATE: Accepts threshold_map to enforce sampling consistency.
        """
        self.symbols = symbols
        self.models_dir = Path("models")
        self.models_dir.mkdir(exist_ok=True)
        
        # 1. Sampling Synchronization
        self.threshold_map = threshold_map if threshold_map else {}

        # 2. State Containers
        self.feature_engineers = {s: OnlineFeatureEngineer(window_size=CONFIG['features']['window_size']) for s in symbols}
        
        # 3. Adaptive Triple Barrier (Per-Symbol Dynamic Configuration)
        tbm_conf = CONFIG['online_learning']['tbm']
        risk_conf = CONFIG.get('risk_management', {})
        
        # V14.0: Standardize risk multiplier
        risk_mult_conf = float(risk_conf.get('stop_loss_atr_mult', 1.5))
        
        # V16.0: Stricter Portfolio Heat (Max 2 correlated pairs)
        self.max_currency_exposure = int(risk_conf.get('max_currency_exposure', 2))
        
        self.labelers = {}
        self.optimized_params = {} # Cache for gates
        
        # --- V11.0 MOMENTUM & GOLDEN TRIO BUFFERS ---
        # We maintain local buffers to calculate Hurst, KER, and RVOL accurately on the fly
        self.window_size_trio = 100
        self.closes_buffer = {s: deque(maxlen=self.window_size_trio) for s in symbols}
        self.volume_buffer = {s: deque(maxlen=self.window_size_trio) for s in symbols}
        self.bb_window = 20
        self.bb_std = CONFIG['phoenix_strategy'].get('bb_std_dev', 1.0) # V16.3: Relaxed to 1.0 for Scalping
        self.bb_buffers = {s: deque(maxlen=self.bb_window) for s in symbols}
        
        # --- SNIPER PROTOCOL BUFFERS ---
        self.sniper_closes = {s: deque(maxlen=200) for s in symbols} # For SMA 200
        self.sniper_rsi = {s: deque(maxlen=15) for s in symbols}      # For RSI 14

        # --- V16.2 NEW FILTERS ---
        # SMA 200 Trend Filter Buffer
        self.sma_window = {s: deque(maxlen=200) for s in symbols}
        # Volatility Gate Buffer (Returns)
        self.returns_window = {s: deque(maxlen=20) for s in symbols}

        for s in symbols:
            # Default from Config
            s_risk = risk_mult_conf
            s_reward = tbm_conf.get('barrier_width', 2.5) # V16.2: Tightened to 2.5 for faster rotation
            
            # V16.0: Default Horizon Reduced to 240m (4h)
            s_horizon = tbm_conf.get('horizon_minutes', 240) 
            
            # --- DYNAMIC PARAMETER LOADING ---
            params_path = self.models_dir / f"best_params_{s}.json"
            if params_path.exists():
                try:
                    with open(params_path, 'r') as f:
                        bp = json.load(f)
                        self.optimized_params[s] = bp 
                        
                        if 'barrier_width' in bp:
                            s_reward = float(bp['barrier_width'])
                        if 'horizon_minutes' in bp:
                            s_horizon = int(bp['horizon_minutes'])
                        
                        if 'risk_per_trade_percent' in bp:
                            if s not in self.optimized_params: self.optimized_params[s] = {}
                            self.optimized_params[s]['risk_per_trade_percent'] = float(bp['risk_per_trade_percent'])
                            
                except Exception as e:
                    logger.warning(f"Failed to load optimized params for {s}: {e}")

            # Initialize Labeler with SPECIFIC params
            self.labelers[s] = AdaptiveTripleBarrier(
                horizon_ticks=s_horizon,
                risk_mult=s_risk,
                reward_mult=s_reward,
                drift_threshold=tbm_conf.get('drift_threshold', 1.5)
            )

        # 3. Models (River Ensembles)
        self.models = {}
        self.meta_labelers = {}
        self.calibrators = {}
        
        # 4. Warm-up State
        self.burn_in_counters = {s: 0 for s in symbols}
        # V16.6: Reduced burn-in limit since we do Pre-Training
        self.burn_in_limit = 5
        
        # V16.20 FIX: HALLUCINATION GUARD
        # Flag to indicate warmup just finished, so we can bridge the gap safely
        self.warmup_gap_bridge = {s: False for s in symbols}
        
        # 5. Forensic Stats
        self.rejection_stats = {s: defaultdict(int) for s in symbols}
        self.feature_stats = {s: defaultdict(float) for s in symbols}
        self.bar_counters = {s: 0 for s in symbols}
        self.feature_importance_counter = {s: Counter() for s in symbols}
        
        # 6. Streak Breaker & Daily Circuit Breaker State
        self.consecutive_losses = {s: 0 for s in symbols}
        self.active_signals = {s: deque() for s in symbols} 
        
        # V10.0: Daily Performance Tracking (Symbol Circuit Breaker)
        self.daily_performance = {s: {'date': None, 'losses': 0, 'pnl': 0.0} for s in symbols}
        
        # V16.0: Scalper Allowance (5 Losses)
        self.daily_max_losses = 5 
        
        # 7. Architecture: Auto-Save Timer
        self.last_save_time = time.time()
        self.save_interval = 300 # 5 Minutes

        # --- Gating Params ---
        self.vol_gate_conf = CONFIG['online_learning'].get('volatility_gate', {})
        self.use_vol_gate = self.vol_gate_conf.get('enabled', True)
        self.min_atr_spread_ratio = self.vol_gate_conf.get('min_atr_spread_ratio', 0.8) # V16.3: Relaxed
        
        self.spread_map = CONFIG.get('forensic_audit', {}).get('spread_pips', {})
        
        # --- PHOENIX STRATEGY PARAMETERS (V16.3) ---
        phx_conf = CONFIG.get('phoenix_strategy', {})
        
        # V16.3 Logic Thresholds (Scalper Tuned)
        self.ker_floor = float(phx_conf.get('ker_trend_threshold', 0.001)) # Relaxed from 0.002
        self.hurst_breakout = float(phx_conf.get('hurst_breakout_threshold', 0.42)) # Relaxed from 0.45
        self.rvol_trigger = float(phx_conf.get('rvol_volatility_trigger', 2.5)) 
        self.require_d1_trend = phx_conf.get('require_d1_trend', False)
        
        self.default_max_rvol = float(phx_conf.get('max_relative_volume', 25.0))
        
        # V12.3: Regime Enforcement Mode (HARD vs SOFT)
        self.regime_enforcement = phx_conf.get('regime_enforcement', 'DISABLED').upper()
        self.asset_regime_map = phx_conf.get('asset_regime_map', {})
        
        # Friday Guard
        self.friday_entry_cutoff = CONFIG['risk_management'].get('friday_entry_cutoff_hour', 18)
        
        # V12.7: ADX Threshold (Cached for Logging)
        adx_cfg = CONFIG.get('features', {}).get('adx', {})
        # V16.6: RELAXED ADX for Scalping (Default to 10 if not set)
        self.adx_threshold = float(adx_cfg.get('threshold', 10.0))

        # Fallback Tracking
        self.l2_missing_warned = {s: False for s in symbols}
        self.last_close_prices = {s: 0.0 for s in symbols}
        
        # Timezone for Guard
        risk_conf = CONFIG.get('risk_management', {})
        tz_str = risk_conf.get('risk_timezone', 'Europe/Prague')
        try:
            self.server_tz = pytz.timezone(tz_str)
        except Exception:
            self.server_tz = pytz.timezone('Europe/Prague')

        # --- REC 1: Dynamic Gate Scaling State ---
        self.ker_drift_detectors = {s: drift.ADWIN(delta=0.01) for s in symbols}
        self.dynamic_ker_offsets = {s: 0.0 for s in symbols}

        # Inject Default Data 
        self._inject_auxiliary_data()

        # Initialize Models & Load State
        self._init_models()
        self._load_state()
        
        # V16.6: PRE-TRAINING WARMUP (CRITICAL)
        self._perform_warmup()

    def _init_models(self):
        """
        Initializes the machine learning pipelines.
        V10.0: Uses AdaptiveRandomForestClassifier with ADWIN drift detection.
        """
        conf = CONFIG['online_learning']
        metric_map = {"LogLoss": metrics.LogLoss(), "F1": metrics.F1(), "Accuracy": metrics.Accuracy(), "ROCAUC": metrics.ROCAUC()}
        selected_metric = metric_map.get(conf.get('metric', 'LogLoss'), metrics.LogLoss())
        
        for sym in self.symbols:
            # V10.0 Upgrade: Adaptive Random Forest
            base_clf = forest.ARFClassifier(
                n_models=conf.get('n_models', 50),
                grace_period=conf['grace_period'],
                delta=conf['delta'],
                split_criterion='gini',
                leaf_prediction='mc',
                max_features=conf.get('max_features', 'sqrt'),
                lambda_value=conf.get('lambda_value', 10),
                metric=selected_metric,
                warning_detector=drift.ADWIN(delta=conf.get('warning_delta', 0.001)),
                drift_detector=drift.ADWIN(delta=conf['delta'])
            )
            
            # Pipeline: Scaler -> Model
            self.models[sym] = compose.Pipeline(
                preprocessing.StandardScaler(),
                base_clf
            )
            self.meta_labelers[sym] = MetaLabeler()
            self.calibrators[sym] = ProbabilityCalibrator()

    def _perform_warmup(self):
        """
        V16.7 PATCH: Synchronized Warm-Up.
        Uses the EXACT same threshold as the Live Engine to prevent data distribution shift.
        Loads 5,000 ticks from DB and pre-trains the model.
        """
        logger.info(f"{LogSymbols.TRAINING} Starting Model Pre-Training (Warm-Up)...")
        
        for sym in self.symbols:
            try:
                # 1. Load Data
                df = load_real_data(sym, n_candles=5000, days=30)
                if df.empty:
                    logger.warning(f"âš ï¸ No historical data for {sym}. Model will start cold.")
                    continue
                
                # 2. Setup Generator (V16.7 SYNC FIX)
                calibrated_thresh = self.threshold_map.get(sym)
                config_thresh = CONFIG['data'].get('volume_bar_threshold', 10.0)
                
                if calibrated_thresh:
                    thresh = calibrated_thresh
                    source = "CALIBRATED"
                else:
                    thresh = config_thresh
                    source = "CONFIG"

                alpha = CONFIG['data'].get('imbalance_alpha', 0.05)
                gen = AdaptiveImbalanceBarGenerator(sym, initial_threshold=thresh, alpha=alpha)
                
                logger.info(f"ðŸ”¥ Pre-training {sym} on {len(df)} ticks... (Thresh: {thresh} [{source}])")
                
                # 3. Simulate Feed
                bars_trained = 0
                for row in df.itertuples():
                    price = getattr(row, 'price', getattr(row, 'close', None))
                    vol = getattr(row, 'volume', 1.0)
                    ts_val = getattr(row, 'Index', None).timestamp()
                    
                    if price is None: continue
                    
                    # Synthetic Flow for Warmup
                    b_vol = getattr(row, 'buy_vol', 0.0)
                    s_vol = getattr(row, 'sell_vol', 0.0)
                    if b_vol == 0 and s_vol == 0:
                        b_vol = vol / 2
                        s_vol = vol / 2
                        
                    bar = gen.process_tick(price, vol, ts_val, b_vol, s_vol)
                    
                    if bar:
                        self._train_on_bar(sym, bar)
                        bars_trained += 1
                
                # V16.20 FIX: THE HALLUCINATOR CURE
                # Mark this symbol as requiring a "Gap Bridge".
                # The first live bar will update EMAs but NOT trigger a signal.
                # This prevents the model from seeing a massive return jump from Historical End -> Live Start.
                self.warmup_gap_bridge[sym] = True
                
                # Force reset of price reference to prevent drift
                self.last_close_prices[sym] = 0.0 
                
                logger.info(f"âœ… {sym} Warm-Up Complete: Trained on {bars_trained} bars. Gap Bridge Armed.")
                
            except Exception as e:
                logger.error(f"âŒ Warm-Up Failed for {sym}: {e}")

    def _train_on_bar(self, symbol: str, bar: VolumeBar):
        """
        Internal method to update Model/FE state without generating trading signals.
        Used exclusively for Warm-Up.
        """
        # Feature Engineering
        fe = self.feature_engineers[symbol]
        labeler = self.labelers[symbol]
        model = self.models[symbol]
        
        # Buffer updates needed for features
        self.closes_buffer[symbol].append(bar.close)
        self.volume_buffer[symbol].append(bar.volume)
        self.bb_buffers[symbol].append(bar.close)
        
        # Simple Flow assumption
        buy_vol = getattr(bar, 'buy_vol', bar.volume/2)
        sell_vol = getattr(bar, 'sell_vol', bar.volume/2)
        
        features = fe.update(
            price=bar.close, timestamp=bar.timestamp.timestamp(), volume=bar.volume,
            high=bar.high, low=bar.low, buy_vol=buy_vol, sell_vol=sell_vol,
            time_feats={'sin_hour':0, 'cos_hour':0} # Simplified for warmup
        )
        
        if features is None: return

        # Calculate Trio
        hurst, ker_val, rvol_val = self._calculate_golden_trio(symbol)
        features['hurst'] = hurst
        features['ker'] = ker_val
        features['rvol'] = rvol_val
        
        # Resolve Labels & Train
        resolved_labels = labeler.resolve_labels(bar.high, bar.low)
        if resolved_labels:
            for (stored_feats, outcome_label, realized_ret) in resolved_labels:
                model.learn_one(stored_feats, outcome_label)
                if outcome_label != 0:
                    model.learn_one(stored_feats, outcome_label) # Reinforce non-noise
        
        # Add Opportunity
        current_atr = features.get('atr', 0.001)
        labeler.add_trade_opportunity(features, bar.close, current_atr, bar.timestamp.timestamp())

    def _calculate_golden_trio(self, symbol: str) -> Tuple[float, float, float]:
        """
        Calculates the "Golden Trio" of features locally using accurate buffers.
        Includes robust math guards against zero-division and log(0).
        """
        closes = self.closes_buffer[symbol]
        vols = self.volume_buffer[symbol]
        
        # Defaults
        hurst = 0.5
        ker = 0.5
        rvol = 1.0
        
        if len(closes) < 30:
            return hurst, ker, rvol

        prices = np.array(closes)
        
        # 1. Simple Hurst (Rescaled Range Proxy)
        try:
            if np.var(prices) < 1e-9:
                hurst = 0.5
            else:
                lags = range(2, 20)
                tau = []
                for lag in lags:
                    diff = np.subtract(prices[lag:], prices[:-lag])
                    std = np.std(diff)
                    tau.append(std if std > 1e-9 else 1e-9)
                
                # Polyfit on log-log
                # V13.1 FIX: Slope = H. Removed legacy scalar.
                poly = np.polyfit(np.log(lags), np.log(tau), 1)
                hurst = poly[0] 
                hurst = max(0.0, min(1.0, hurst))
        except:
            hurst = 0.5

        # 2. KER (Efficiency Ratio)
        try:
            diffs = np.diff(prices)
            net_change = abs(prices[-1] - prices[0])
            sum_changes = np.sum(np.abs(diffs))
            # V13.1 FIX: Strict Zero Division Guard
            if sum_changes > 1e-9:
                ker = net_change / sum_changes
            else:
                ker = 0.0
        except:
            ker = 0.0

        # 3. RVOL
        if len(vols) > 10:
            curr_vol = vols[-1]
            avg_vol = np.mean(list(vols)[:-1]) # Exclude current
            # V13.1 FIX: Strict Zero Division Guard
            if avg_vol > 1e-9:
                rvol = curr_vol / avg_vol
            else:
                rvol = 1.0
        
        return hurst, ker, rvol

    def _calculate_trend_bias(self, symbol: str, current_price: float) -> int:
        """
        V16.2: Returns 1 (Bullish), -1 (Bearish), or 0 (Neutral).
        Based on Price vs SMA(200). Helps align Scalps with Macro Trend.
        """
        buffer = self.sma_window[symbol]
        if len(buffer) < 200:
            return 0 # Not enough data
            
        sma_200 = sum(buffer) / 200
        
        # 0.05% Filter Buffer to avoid noise around the MA
        threshold = sma_200 * 0.0005
        
        if current_price > (sma_200 + threshold):
            return 1
        elif current_price < (sma_200 - threshold):
            return -1
        else:
            return 0

    def _check_volatility_condition(self, symbol: str, current_price: float) -> bool:
        """
        V16.2: Ensures distinct market movement exists before entering.
        Prevents entering during dead zones where spreads kill profit.
        """
        buffer = self.returns_window[symbol]
        if len(buffer) < 10:
            return True # Allow early trades
            
        # Calculate Volatility (Std Dev of Returns)
        vol = np.std(list(buffer))
        
        # Minimum Volatility Threshold (approx 1.5 pips movement per bar)
        MIN_VOLATILITY = 0.00015 
        
        if vol < MIN_VOLATILITY:
            return False
            
        return True

    def _calibrate_confidence(self, raw_conf: float) -> float:
        """
        Calibrates raw model probability to a more reliable confidence score.
        """
        # Center around 0.5
        x = (raw_conf - 0.5) * 10.0 
        calibrated = 1 / (1 + np.exp(-x))
        return calibrated

    def _get_preferred_regime(self, symbol: str) -> str:
        """
        V12.2: ROBUST ASSET PERSONALITY DETECTION.
        Prevents 'USD' (Neutral) from overriding 'CAD' (MeanRev) in USDCAD.
        Logic: Trend > MeanReversion > Neutral.
        """
        # 1. Check for Exact Match
        if symbol in self.asset_regime_map:
            return self.asset_regime_map[symbol]
        
        # 2. Scan Components (Priority Logic)
        regimes_found = []
        for key, regime in self.asset_regime_map.items():
            if key in symbol:
                regimes_found.append(regime)
        
        # Priority 1: Trend Breakout
        if "TREND_BREAKOUT" in regimes_found:
            return "TREND_BREAKOUT"
            
        # Priority 2: Mean Reversion
        if "MEAN_REVERSION" in regimes_found:
            return "MEAN_REVERSION"
            
        # Priority 3: Neutral (Default for EURUSD if defined as such)
        return "NEUTRAL"

    def _check_currency_exposure(self, symbol: str, open_positions: Dict[str, Any]) -> bool:
        """
        V12.3: Enforces Portfolio Heat Limits.
        Prevents stacking too much risk on one currency (e.g. max 2 USD pairs).
        """
        base_ccy = symbol[:3]
        quote_ccy = symbol[3:]
        
        base_count = 0
        quote_count = 0
        
        for sym in open_positions:
            pos_base = sym[:3]
            pos_quote = sym[3:]
            
            if base_ccy == pos_base or base_ccy == pos_quote:
                base_count += 1
            if quote_ccy == pos_base or quote_ccy == pos_quote:
                quote_count += 1
        
        if base_count >= self.max_currency_exposure:
            self.rejection_stats[symbol][f"Max Exposure ({base_ccy})"] += 1
            return False
            
        if quote_count >= self.max_currency_exposure:
            self.rejection_stats[symbol][f"Max Exposure ({quote_ccy})"] += 1
            return False
            
        return True

    def process_bar(self, symbol: str, bar: VolumeBar, context_data: Dict[str, Any] = None) -> Optional[Signal]:
        """
        Actual entry point called by Engine.
        Executes the Learn-Predict Loop with Project Phoenix V16.3 Logic.
        Enforces Asset-Specific Regimes (The "Personality Filter").
        """
        if symbol not in self.symbols: return None
        
        # --- AUTO SAVE CHECK ---
        if time.time() - self.last_save_time > self.save_interval:
            self.save_state()
            self.last_save_time = time.time()

        fe = self.feature_engineers[symbol]
        labeler = self.labelers[symbol]
        model = self.models[symbol]
        meta_labeler = self.meta_labelers[symbol]
        stats = self.rejection_stats[symbol]
        feat_stats = self.feature_stats[symbol]
        
        self.bar_counters[symbol] += 1
        
        # V16.20 FIX: GAP BRIDGING (HALLUCINATOR CURE)
        # If we just finished warmup, the 'last_price' in FE is stale (from history).
        # We must treat this bar as a bridge: update state, but DO NOT predict.
        is_bridging_gap = False
        if self.warmup_gap_bridge[symbol]:
            is_bridging_gap = True
            logger.info(f"ðŸŒ‰ BRIDGING GAP {symbol}: Syncing Live Price {bar.close:.5f} (Skipping Signal)")
            # Turn off the flag so next bar is normal
            self.warmup_gap_bridge[symbol] = False
            # Force update last_price to current, so next return is valid
            self.last_close_prices[symbol] = bar.close
        
        # Capture previous close before updating with current bar
        prev_close = self.last_close_prices.get(symbol, bar.close)
        self.last_close_prices[symbol] = bar.close

        # --- UPDATE BUFFERS ---
        self.closes_buffer[symbol].append(bar.close)
        self.volume_buffer[symbol].append(bar.volume)
        
        # V16.2: Update Trend Filter Buffer
        self.sma_window[symbol].append(bar.close)
        
        # V16.2: Update Returns Buffer for Volatility Gate
        if len(self.sma_window[symbol]) >= 2:
             prev_p = self.sma_window[symbol][-2]
             if prev_p > 0:
                 ret = math.log(bar.close / prev_p)
                 self.returns_window[symbol].append(ret)

        self.sniper_closes[symbol].append(bar.close)
        if len(self.sniper_closes[symbol]) > 1:
            delta = self.sniper_closes[symbol][-1] - self.sniper_closes[symbol][-2]
            self.sniper_rsi[symbol].append(delta)
        self.bb_buffers[symbol].append(bar.close)

        # Extract Flows (Ensuring they are populated from Engine)
        buy_vol = getattr(bar, 'buy_vol', 0.0)
        sell_vol = getattr(bar, 'sell_vol', 0.0)
        
        # Retail Fallback (Tick Rule approximation if L2 missing or zero)
        if buy_vol == 0 and sell_vol == 0:
            if not self.l2_missing_warned[symbol]:
                logger.warning(f"âš ï¸ {symbol}: Zero Flow Detected in Bar. Using Local Tick Rule.")
                self.l2_missing_warned[symbol] = True
            
            # Synthetic Volume Floor
            effective_vol = bar.volume if bar.volume > 0 else 1.0
            
            if bar.close > prev_close: 
                buy_vol = effective_vol
                sell_vol = 0.0
            elif bar.close < prev_close: 
                buy_vol = 0.0
                sell_vol = effective_vol
            else: 
                buy_vol = effective_vol / 2.0
                sell_vol = effective_vol / 2.0
        
        self.last_price = bar.close

        # A. Feature Engineering (Standard)
        features = fe.update(
            price=bar.close,
            timestamp=bar.timestamp.timestamp(),
            volume=bar.volume,
            high=bar.high,
            low=bar.low,
            buy_vol=buy_vol,
            sell_vol=sell_vol,
            time_feats={},
            context_data=context_data
        )
        
        if features is None: return None
        
        # --- V12.0: GOLDEN TRIO CALCULATION ---
        hurst, ker_val, rvol_val = self._calculate_golden_trio(symbol)
        
        # Inject into features for model training
        features['hurst'] = hurst
        features['ker'] = ker_val
        features['rvol'] = rvol_val
        
        # Extract for Gates
        parkinson = features.get('parkinson_vol', 0.0)

        # --- REC 1: DYNAMIC GATE SCALING ---
        self.ker_drift_detectors[symbol].update(ker_val)
        if self.ker_drift_detectors[symbol].drift_detected:
            self.dynamic_ker_offsets[symbol] = max(-0.10, self.dynamic_ker_offsets[symbol] - 0.05)
        else:
            self.dynamic_ker_offsets[symbol] = min(0.0, self.dynamic_ker_offsets[symbol] + 0.001)

        feat_stats['avg_ker'] = (0.99) * feat_stats.get('avg_ker', 0.5) + 0.01 * ker_val
        feat_stats['avg_rvol'] = (0.99) * feat_stats.get('avg_rvol', 1.0) + 0.01 * rvol_val
        
        # --- WARM-UP GATE ---
        if self.burn_in_counters[symbol] < self.burn_in_limit:
            self.burn_in_counters[symbol] += 1
            return Signal(symbol, "WARMUP", 0.0, {})

        # --- V16.20 GAP BRIDGE EXECUTION ---
        if is_bridging_gap:
            # We processed the features to update EMAs, but we RETURN now.
            # This ensures the model logic never sees the "gap return".
            return Signal(symbol, "HOLD", 0.0, {"reason": "Bridging Gap"})

        # --- SERVER TIME & DAILY STATS MANAGEMENT ---
        server_time = bar.timestamp.astimezone(self.server_tz)
        current_date = server_time.date()
        
        # Reset Daily Stats if New Day
        if self.daily_performance[symbol]['date'] != current_date:
            self.daily_performance[symbol] = {'date': current_date, 'losses': 0, 'pnl': 0.0}

        # --- V14.0 CIRCUIT BREAKER (Aggressor) ---
        # Increased to 5 losses to prevent early lockout
        if self.daily_performance[symbol]['losses'] >= self.daily_max_losses:
            stats["Circuit Breaker (Daily Losses)"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Circuit Breaker Active"})

        # 2. Delayed Training (Label Resolution)
        resolved_labels = labeler.resolve_labels(bar.high, bar.low)
        
        if resolved_labels:
            for (stored_feats, outcome_label, realized_ret) in resolved_labels:
                
                # --- UPDATE PERFORMANCE METRICS ---
                if outcome_label != 0:
                    self.daily_performance[symbol]['pnl'] += realized_ret
                    # Count as loss if realized return is negative (slippage included)
                    if realized_ret < 0:
                        self.daily_performance[symbol]['losses'] += 1
                        logger.info(f"ðŸ“‰ LOSS DETECTED {symbol}: ${realized_ret:.2f} | Daily Losses: {self.daily_performance[symbol]['losses']}")
                
                # --- STREAK BREAKER UPDATE ---
                if self.active_signals[symbol]:
                    _ = self.active_signals[symbol].popleft()
                    if outcome_label == 1: self.consecutive_losses[symbol] = 0
                    elif outcome_label == -1: self.consecutive_losses[symbol] += 1

                # --- LEARNING ---
                w_pos = CONFIG['online_learning'].get('positive_class_weight', 1.5)
                w_neg = CONFIG['online_learning'].get('negative_class_weight', 1.0)
                base_weight = w_pos if outcome_label != 0 else w_neg
                
                ret_scalar = math.log1p(abs(realized_ret) * 100.0)
                ret_scalar = max(0.5, min(ret_scalar, 5.0))
                
                # Use Historical KER for weighting
                hist_ker = stored_feats.get('ker', 0.5)
                ker_weight = hist_ker * 2.0 
                
                final_weight = base_weight * ret_scalar * ker_weight
                
                # V16.20 FIX: Ensure features are strictly floats for River
                clean_stored = {k: float(v) for k, v in stored_feats.items()}
                
                model.learn_one(clean_stored, outcome_label, sample_weight=final_weight)
                if outcome_label != 0:
                      model.learn_one(clean_stored, outcome_label, sample_weight=final_weight * 1.5)
                if outcome_label != 0:
                    meta_labeler.update(clean_stored, primary_action=outcome_label, outcome_pnl=realized_ret)

        # 3. Add Trade Opportunity
        current_atr = features.get('atr', 0.0)
        features['parkinson_vol'] = parkinson 
        labeler.add_trade_opportunity(features, bar.close, current_atr, bar.timestamp.timestamp(), parkinson_vol=parkinson)

        # D. ACTIVE TRADE MANAGEMENT (Local check)
        open_positions = context_data.get('positions', {}) if context_data else {}
        
        # V16.14 FIX: PROFITABILITY CHECK FOR PYRAMIDING
        is_pyramid_attempt = False
        
        if symbol in open_positions:
            pos = open_positions[symbol]
            pyramid_config = CONFIG.get('risk_management', {}).get('pyramiding', {})
            
            # 1. Check if Enabled
            if not pyramid_config.get('enabled', False):
                return None # Standard Blocking (No pyramiding allowed)
            
            # 2. Check Profitability (CRITICAL FIX)
            try:
                entry_price = float(pos.get('entry_price', 0.0))
                sl_price = float(pos.get('sl', 0.0))
                pos_type = str(pos.get('type', '')).upper()
                current_price = bar.close
                
                # Default "BUY" if type missing (unlikely)
                if pos_type not in ["BUY", "SELL"]: pos_type = "BUY"

                if entry_price > 0 and sl_price > 0:
                    risk_dist = abs(entry_price - sl_price)
                    
                    current_r = 0.0
                    if pos_type == "BUY":
                        pnl_dist = current_price - entry_price
                        current_r = pnl_dist / risk_dist if risk_dist > 0 else 0
                    elif pos_type == "SELL":
                        pnl_dist = entry_price - current_price
                        current_r = pnl_dist / risk_dist if risk_dist > 0 else 0
                        
                    required_r = float(pyramid_config.get('add_on_profit_r', 0.5))
                    
                    if current_r < required_r:
                        # Trade is not profitable enough (or is losing). BLOCK.
                        # This prevents adding to losers.
                        return None 
                    
                    # If we reach here, trade IS profitable enough. 
                    # We set the flag and proceed to signal generation.
                    is_pyramid_attempt = True
                else:
                    # Data missing, safe block
                    return None
            except Exception:
                return None

        # ============================================================
        # 4. PHOENIX V16.3: AGGRESSOR PROTOCOL WITH NEW GATES
        # ============================================================
        
        max_rvol_thresh = self.default_max_rvol
        
        # FRIDAY GUARD
        if server_time.weekday() == 4 and server_time.hour >= self.friday_entry_cutoff:
             return Signal(symbol, "HOLD", 0.0, {"reason": "Friday Entry Guard"})

        # G1: EFFICIENCY (KER) - AGGRESSIVE (V16.3)
        # Reduced floor to 0.001 to catch early GBP moves
        base_thresh = self.ker_floor 
        effective_ker_thresh = max(0.001, base_thresh + self.dynamic_ker_offsets[symbol])

        if ker_val < effective_ker_thresh:
            stats[f"Low Efficiency"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": f"Low Efficiency (KER {ker_val:.3f} < {effective_ker_thresh:.3f})"})

        # G2: REGIME IDENTIFICATION (UNSHACKLED)
        # V16.6: If Regime Enforcement is DISABLED, we treat this purely as a technical filter (BB)
        preferred_regime = self._get_preferred_regime(symbol)
        regime_label = "Neutral"
        proposed_action = 0 # 0=Hold, 1=Buy, -1=Sell
        is_regime_clash = False
        
        # Check Bollinger Bands state for signals
        if len(self.bb_buffers[symbol]) < self.bb_window:
            return Signal(symbol, "HOLD", 0.0, {"reason": "Warming Up BB"})
            
        bb_mu = np.mean(self.bb_buffers[symbol])
        bb_std = np.std(self.bb_buffers[symbol])
        bb_mult = self.bb_std 
        
        upper_bb = bb_mu + (bb_mult * bb_std)
        lower_bb = bb_mu - (bb_mult * bb_std)
        
        # --- V14.0 LOGIC MAPPING: TREND ONLY ---
        is_trending = hurst > self.hurst_breakout
        
        if is_trending:
            if preferred_regime == "MEAN_REVERSION":
                is_regime_clash = True
            
            # Trend Logic
            regime_label = "TREND_BREAKOUT"
            if bar.close > upper_bb:
                proposed_action = 1 # Breakout Buy
            elif bar.close < lower_bb:
                proposed_action = -1 # Breakout Sell
                
        else:
            # NEUTRAL ZONE / MEAN REVERSION POTENTIAL
            # V16.6: If we disable regime enforcement, allow Mean Reversion on Low Hurst
            if self.regime_enforcement == "DISABLED":
                 # Low Hurst = Reversion. If hitting bands, fade it.
                 regime_label = "MEAN_REVERSION"
                 if bar.close > upper_bb:
                     proposed_action = -1 # Reversion Sell
                 elif bar.close < lower_bb:
                     proposed_action = 1  # Reversion Buy
            else:
                stats[f"Random Walk Regime (H={hurst:.2f})"] += 1
                return Signal(symbol, "HOLD", 0.0, {"reason": f"Random Walk (Hurst {hurst:.2f})"})

        if proposed_action == 0:
            stats["No Trigger"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "No BB Trigger in Regime"})
            
        # --- V16.2 GATE: VOLATILITY EXPANSION ---
        # Prevents entries in low-volatility dead zones where time stops kill trades.
        if not self._check_volatility_condition(symbol, bar.close):
            stats["Low Volatility (Dead Zone)"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Low Volatility (Dead Zone)"})

        # --- REGIME ENFORCEMENT ---
        if is_regime_clash:
            if self.regime_enforcement == "HARD":
                stats["Personality Clash (Hard Block)"] += 1
                return Signal(symbol, "HOLD", 0.0, {"reason": "Asset Personality Clash"})
            elif self.regime_enforcement == "DISABLED":
                 # V14.0: Bypass clash flag to allow full adaptability
                 is_regime_clash = False 
            else:
                # SOFT Mode: Mark for high confidence check later
                pass 

        # G3: EXHAUSTION
        if rvol_val > max_rvol_thresh:
            stats[f"Volume Climax"] += 1
            return Signal(symbol, "HOLD", 0.0, {"reason": "Volume Climax"})
            
        # G4: TREND STRENGTH (ADX) - Only for Trend Regime
        if regime_label == "TREND_BREAKOUT":
            adx_val = features.get('adx', 0.0)
            if adx_val < self.adx_threshold: 
                # V16.6 UPDATE: Just log warning, don't block hard if other signals strong
                stats[f"Weak Trend (ADX {adx_val:.1f} < {self.adx_threshold})"] += 1
                # return Signal(symbol, "HOLD", 0.0, {"reason": f"Weak Trend (ADX {adx_val:.1f})"})

        # 5. ML Confirmation & Calibration
        # V16.20 FIX: Ensure features are floats
        clean_features = {k: float(v) for k, v in features.items()}
        
        pred_proba = model.predict_proba_one(clean_features)
        
        # Extract probability for the proposed action
        # River returns dict {label: prob}
        prob_success = pred_proba.get(proposed_action, 0.0)
        
        # V14.0 SURVIVAL: Bypass Calibration/Confidence Check
        # We trust the Meta Labeler and Regime Filters entirely.
        confidence = 1.0 # Force max confidence to bypass filters
        
        meta_threshold = CONFIG['online_learning'].get('meta_labeling_threshold', 0.55) 
        is_profitable = meta_labeler.predict(clean_features, proposed_action, threshold=meta_threshold)

        # --- EXECUTION WITH DYNAMIC CONFIDENCE ---
        
        if is_regime_clash:
            pass 

        # --- SNIPER PROTOCOL: FINAL FILTER GATE (V14.0 MOMENTUM IGNITION) ---
        d1_ema = context_data.get('d1', {}).get('ema200', 0.0) if context_data else 0.0
        
        # NOTE: Passing 'hurst' now to check for Ignition
        if not self._check_sniper_filters(symbol, proposed_action, bar.close, d1_ema, hurst):
            stats["Sniper Reject (Trend/RSI)"] += 1
            return Signal(symbol, "HOLD", confidence, {"reason": "Sniper Filter Reject"})
        # ------------------------------------------

        # --- V12.3: PORTFOLIO HEAT CHECK ---
        if not self._check_currency_exposure(symbol, open_positions):
            return Signal(symbol, "HOLD", confidence, {"reason": "Max Currency Exposure"})

        if is_profitable:
                action_str = "BUY" if proposed_action == 1 else "SELL"
                self.active_signals[symbol].append(action_str)
                
                imp_feats = []
                imp_feats.append(regime_label)
                if rvol_val > 2.0: imp_feats.append('High_Fuel')
                if hurst > 0.6: imp_feats.append('High_Hurst')
                
                for f in imp_feats:
                    self.feature_importance_counter[symbol][f] += 1
                
                opt_rr = self.labelers[symbol].reward_mult
                
                # V14.0 DYNAMIC REWARD: HIGH FUEL = HIGH REWARD
                # If Volume is exploding (Ignition), aim for 4R
                if rvol_val > 3.0:
                    opt_rr = max(opt_rr, 4.0)

                opt_risk = self.optimized_params.get(symbol, {}).get('risk_per_trade_percent')
                
                # V10.2: Tighten Stops Logic (RVOL Trigger)
                tighten_stops = (rvol_val > self.rvol_trigger)

                return Signal(symbol, action_str, confidence, {
                    "meta_ok": True,
                    "volatility": features.get('volatility', 0.001),
                    "atr": current_atr,
                    "ker": ker_val,
                    "parkinson_vol": parkinson,
                    "rvol": rvol_val,
                    "hurst": hurst,
                    "amihud": features.get('amihud', 0.0),
                    "regime": regime_label,
                    "drivers": imp_feats,
                    "optimized_rr": opt_rr,
                    "risk_percent_override": opt_risk,
                    "pyramid": is_pyramid_attempt, # V15.0 Flag
                    "tighten_stops": tighten_stops 
                })
        else:
            stats['Meta Rejected'] += 1
            # V16.7 DIAGNOSTIC LOGGING: Log Shadow Mode probability
            if self.bar_counters[symbol] % 50 == 0:
                logger.info(f"ðŸ”Ž SHADOW MODE {symbol}: Rejected {proposed_action} (Meta Prob: {prob_success:.2f} < {meta_threshold})")
            return Signal(symbol, "HOLD", confidence, {"reason": f"Meta Rejected (Prob {prob_success:.2f})"})

        if self.bar_counters[symbol] % 250 == 0:
            logger.info(f"ðŸ” {symbol} Stats: KER:{feat_stats['avg_ker']:.2f} Streak:{self.consecutive_losses[symbol]}")
            logger.info(f"ðŸ” {symbol} Rejections: {dict(stats)}")
            stats.clear()
            
        return Signal(symbol, "HOLD", confidence, {})

    def _check_sniper_filters(self, symbol: str, signal: int, price: float, d1_ema: float, current_hurst: float) -> bool:
        """
        V14.0 SNIPER PROTOCOL (AGGRESSOR UPDATE):
        1. Trend Filter: D1 Alignment (DISABLED in Config).
        2. RSI Guard: UNLOCKED via Momentum Ignition.
           - If RSI > 80 AND Hurst > 0.60, Trade is ALLOWED (Ignition).
           - Only blocks if RSI > 80 and Hurst < 0.60 (Exhaustion).
        """
        # 1. RSI CALCULATION (M5 Extension)
        if len(self.sniper_rsi[symbol]) < 14:
            rsi = 50.0 
        else:
            gains = [x for x in self.sniper_rsi[symbol] if x > 0]
            losses = [abs(x) for x in self.sniper_rsi[symbol] if x < 0]
            avg_gain = sum(gains) / 14 if gains else 0
            avg_loss = sum(losses) / 14 if losses else 1e-9
            rs = avg_gain / avg_loss
            rsi = 100 - (100 / (1 + rs))

        # 2. TREND FILTER (D1 Bias)
        # V16.6: Explicitly Disabled check to allow Mean Reversion scalps
        # if self.require_d1_trend and d1_ema > 0: ... (Commented out logic)
        
        # 3. RSI EXTREME GUARD (V14.0 MOMENTUM IGNITION)
        # We invert the logic: High RSI + High Hurst = IGNITION (Buy!)
        if "JPY" in symbol:
            pass # JPY pairs trend hard, ignore RSI extremes
        else:
            if signal == 1: # BUY
                if rsi > 80: 
                    # V14.0 CHECK: Is this Exhaustion or Ignition?
                    if current_hurst > 0.60:
                        pass # IGNITION: ALLOW TRADE (Momentum is huge)
                    else:
                        return False # EXHAUSTION: Reject Overbought
            
            elif signal == -1: # SELL
                if rsi < 20: 
                    # V14.0 CHECK: Ignition?
                    if current_hurst > 0.60:
                        pass # IGNITION: ALLOW TRADE (Crash mode)
                    else:
                        return False # EXHAUSTION: Reject Oversold
        
        return True

    def _inject_auxiliary_data(self):
        """Injects static approximations ONLY if missing."""
        # V16.0: Added High-Beta Crosses (EURAUD, GBPNZD) for fallback
        defaults = {
            "USDJPY": 150.0, "GBPUSD": 1.25, "EURUSD": 1.08,
            "USDCAD": 1.35, "USDCHF": 0.90, "AUDUSD": 0.65, "NZDUSD": 0.60,
            "GBPJPY": 190.0, "EURJPY": 160.0, "AUDJPY": 95.0, 
            "GBPAUD": 1.95, 
            "EURAUD": 1.65, # Added
            "GBPNZD": 2.05  # Added
        }
        for sym, price in defaults.items():
            if sym not in self.last_close_prices or self.last_close_prices[sym] == 0:
                self.last_close_prices[sym] = price

    def save_state(self):
        """Saves models AND Feature Engineers to disk."""
        try:
            for sym in self.symbols:
                with open(self.models_dir / f"river_pipeline_{sym}.pkl", "wb") as f:
                    pickle.dump(self.models[sym], f)
                with open(self.models_dir / f"meta_model_{sym}.pkl", "wb") as f:
                    pickle.dump(self.meta_labelers[sym], f)
                with open(self.models_dir / f"calibrators_{sym}.pkl", "wb") as f:
                    pickle.dump(self.calibrators[sym], f)
                
                with open(self.models_dir / f"feature_engineer_{sym}.pkl", "wb") as f:
                    pickle.dump(self.feature_engineers[sym], f)
                    
            logger.info(f"{LogSymbols.DATABASE} Models & State Auto-Saved.")
        except Exception as e:
            logger.error(f"{LogSymbols.ERROR} Failed to save models: {e}")

    def _load_state(self):
        """Loads models AND Feature Engineers from disk."""
        loaded_count = 0
        for sym in self.symbols:
            model_path = self.models_dir / f"river_pipeline_{sym}.pkl"
            meta_path = self.models_dir / f"meta_model_{sym}.pkl"
            fe_path = self.models_dir / f"feature_engineer_{sym}.pkl"
            
            if model_path.exists():
                try:
                    with open(model_path, "rb") as f: self.models[sym] = pickle.load(f)
                    loaded_count += 1
                except Exception: pass
            
            if meta_path.exists():
                try:
                    with open(meta_path, "rb") as f: self.meta_labelers[sym] = pickle.load(f)
                except Exception: pass
            
            if fe_path.exists():
                try:
                    with open(fe_path, "rb") as f: self.feature_engineers[sym] = pickle.load(f)
                    logger.info(f"Loaded Feature State for {sym}")
                except Exception: pass
            
        if loaded_count > 0:
            logger.info(f"{LogSymbols.SUCCESS} Loaded {loaded_count} existing models.")